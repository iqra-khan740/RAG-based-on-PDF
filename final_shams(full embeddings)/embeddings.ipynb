{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3425d0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "def load_text():\n",
    "    loader = PyPDFLoader(\"forty_rules_of_love.pdf\")\n",
    "    return loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f96ae8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading text...\n",
      "Creating chunks...\n",
      "Total chunks created: 1248\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1828\\3162336088.py:63: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedder = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Layer 1 (chunk embeddings)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer 1 Embedding: 100%|██████████| 1248/1248 [01:05<00:00, 19.19it/s]\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1828\\3162336088.py:37: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"ollama3:4b\")  # replace with deepseek-r1:1.5b if needed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 saved at 'faiss_layer1'\n",
      "\n",
      "\n",
      "Summarizing chunks (Layer 2)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk summaries:   0%|          | 0/1248 [00:00<?, ?it/s]C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1828\\3162336088.py:48: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  summary = chain.run([chunk])\n",
      "Chunk summaries: 100%|██████████| 1248/1248 [42:48<00:00,  2.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Layer 2 (summary embeddings)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer 2 Embedding: 100%|██████████| 1248/1248 [00:51<00:00, 24.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 2 saved at 'faiss_layer2'\n",
      "\n",
      "✅ Multi-layered embeddings built successfully!\n"
     ]
    }
   ],
   "source": [
    "# embeddings_builder.py\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm  # progress bars\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import Ollama\n",
    "from langchain.schema import Document\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "DATA_PATH = r\"40_Rules_of_Love.pdf\"  # Updated path\n",
    "LAYER1_DB = \"faiss_layer1\"\n",
    "LAYER2_DB = \"faiss_layer2\"\n",
    "CHUNK_SIZE = 600\n",
    "CHUNK_OVERLAP = 100\n",
    "# ----------------------------\n",
    "\n",
    "# Check GPU availability\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Current CUDA device: {torch.cuda.current_device()}\")\n",
    "    print(f\"Device name: {torch.cuda.get_device_name()}\")\n",
    "\n",
    "def load_text():\n",
    "    \"\"\"Load PDF text from file.\"\"\"\n",
    "    loader = PyPDFLoader(DATA_PATH)\n",
    "    return loader.load()\n",
    "\n",
    "def create_chunks(docs):\n",
    "    \"\"\"Split text into overlapping chunks.\"\"\"\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=CHUNK_SIZE,\n",
    "        chunk_overlap=CHUNK_OVERLAP,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \" \", \"\"]\n",
    "    )\n",
    "    return splitter.split_documents(docs)\n",
    "\n",
    "def summarise_chunks(chunks):\n",
    "    \"\"\"Summarise each chunk using Ollama with progress tracking.\"\"\"\n",
    "    llm = Ollama(model=\"gemma3:4b\")  # replace with deepseek-r1:1.5b if needed\n",
    "    summary_prompt = PromptTemplate(\n",
    "        input_variables=[\"text\"],\n",
    "        template=\"Summarise this text in 3-4 lines, focus on timeline, characters, and events:\\n\\n{text}\"\n",
    "    )\n",
    "    chain = load_summarize_chain(llm, chain_type=\"stuff\", prompt=summary_prompt)\n",
    "\n",
    "    summaries = []\n",
    "    print(\"\\nSummarizing chunks (Layer 2)...\")\n",
    "    for i, chunk in enumerate(tqdm(chunks, desc=\"Chunk summaries\")):\n",
    "        try:\n",
    "            summary = chain.run([chunk])\n",
    "        except Exception as e:\n",
    "            summary = f\"Error summarising chunk {i}: {e}\"\n",
    "        summaries.append(summary)\n",
    "    return summaries\n",
    "\n",
    "def build_embeddings():\n",
    "    \"\"\"Build multi-layered embeddings with progress tracking.\"\"\"\n",
    "    print(\"Loading text...\")\n",
    "    docs = load_text()\n",
    "\n",
    "    print(\"Creating chunks...\")\n",
    "    chunks = create_chunks(docs)\n",
    "    print(f\"Total chunks created: {len(chunks)}\\n\")\n",
    "\n",
    "    # Initialize embeddings with GPU support\n",
    "    embedder = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        model_kwargs={\"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"}\n",
    "    )\n",
    "\n",
    "    # ---------- Layer 1: Chunk embeddings ----------\n",
    "    print(\"Building Layer 1 (chunk embeddings)...\")\n",
    "    chunk_embeddings = []\n",
    "    for i, chunk in enumerate(tqdm(chunks, desc=\"Layer 1 Embedding\")):\n",
    "        emb = embedder.embed_documents([chunk.page_content])[0]  # compute embedding for this chunk\n",
    "        chunk_embeddings.append(Document(page_content=chunk.page_content, metadata=chunk.metadata))\n",
    "    \n",
    "    # Create FAISS database with GPU acceleration\n",
    "    db1 = FAISS.from_documents(chunk_embeddings, embedder)\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(LAYER1_DB, exist_ok=True)\n",
    "    db1.save_local(LAYER1_DB)\n",
    "    print(f\"Layer 1 saved at '{LAYER1_DB}'\\n\")\n",
    "\n",
    "    # ---------- Layer 2: Summary embeddings ----------\n",
    "    summaries = summarise_chunks(chunks)\n",
    "    summary_docs = [\n",
    "        Document(page_content=s, metadata={\"type\": \"summary\", \"chunk_id\": i})\n",
    "        for i, s in enumerate(summaries)\n",
    "    ]\n",
    "\n",
    "    print(\"Building Layer 2 (summary embeddings)...\")\n",
    "    summary_embeddings = []\n",
    "    for i, doc in enumerate(tqdm(summary_docs, desc=\"Layer 2 Embedding\")):\n",
    "        emb = embedder.embed_documents([doc.page_content])[0]\n",
    "        summary_embeddings.append(Document(page_content=doc.page_content, metadata=doc.metadata))\n",
    "    \n",
    "    # Create FAISS database with GPU acceleration\n",
    "    db2 = FAISS.from_documents(summary_embeddings, embedder)\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(LAYER2_DB, exist_ok=True)\n",
    "    db2.save_local(LAYER2_DB)\n",
    "    print(f\"Layer 2 saved at '{LAYER2_DB}'\\n\")\n",
    "\n",
    "    print(\"✅ Multi-layered embeddings built successfully!\")\n",
    "    print(f\"GPU was used for embeddings: {torch.cuda.is_available()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    build_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2594d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Madam\\Shams\\final_shams\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_8696\\969100407.py:8: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_8696\\969100407.py:9: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"gemma3:4b\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks to summarize: 1248\n",
      "\n",
      "⚠ Failed chunk 1/1248 (ID: 657db385-8fa7-4ce6-af78-90f50c30ab4e): HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000297D9211F50>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n",
      "⚠ Failed chunk 2/1248 (ID: 8acd40df-d979-41bd-9081-3e93d5956590): HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000297D92AA490>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n",
      "⚠ Failed chunk 3/1248 (ID: dc219ba5-7ed4-4560-8e04-2ce826d2e900): HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000297D9283350>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n",
      "⚠ Failed chunk 4/1248 (ID: 3416d395-6613-4db2-9699-ce0d517d2de5): HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000297D9270D90>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConnectionRefusedError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Madam\\Shams\\final_shams\\.venv\\Lib\\site-packages\\urllib3\\util\\connection.py:73\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, socket_options)\u001b[39m\n\u001b[32m     72\u001b[39m     sock.bind(source_address)\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m sock.connect(sa)\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[31mConnectionRefusedError\u001b[39m: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     22\u001b[39m chunk = raw_docstore._dict[doc_id]  \u001b[38;5;66;03m# get the actual text\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     summary = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSummarize this chunk factually and do not add any fictional events: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mchunk\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m     summary_texts.append({\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m: doc_id, \u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m: summary})\n\u001b[32m     28\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✅ Chunk \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_chunks\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m summarized. Total summaries so far: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(summary_texts)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Madam\\Shams\\final_shams\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:390\u001b[39m, in \u001b[36mBaseLLM.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    379\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    380\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    381\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    386\u001b[39m     **kwargs: Any,\n\u001b[32m    387\u001b[39m ) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    388\u001b[39m     config = ensure_config(config)\n\u001b[32m    389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m390\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    400\u001b[39m         .generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m]\n\u001b[32m    401\u001b[39m         .text\n\u001b[32m    402\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Madam\\Shams\\final_shams\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:789\u001b[39m, in \u001b[36mBaseLLM.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    780\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    781\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    782\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    786\u001b[39m     **kwargs: Any,\n\u001b[32m    787\u001b[39m ) -> LLMResult:\n\u001b[32m    788\u001b[39m     prompt_strings = [p.to_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Madam\\Shams\\final_shams\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:1000\u001b[39m, in \u001b[36mBaseLLM.generate\u001b[39m\u001b[34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    985\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    986\u001b[39m     run_managers = [\n\u001b[32m    987\u001b[39m         callback_manager.on_llm_start(\n\u001b[32m    988\u001b[39m             \u001b[38;5;28mself\u001b[39m._serialized,\n\u001b[32m   (...)\u001b[39m\u001b[32m    998\u001b[39m         )\n\u001b[32m    999\u001b[39m     ]\n\u001b[32m-> \u001b[39m\u001b[32m1000\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) > \u001b[32m0\u001b[39m:\n\u001b[32m   1008\u001b[39m     run_managers = [\n\u001b[32m   1009\u001b[39m         callback_managers[idx].on_llm_start(\n\u001b[32m   1010\u001b[39m             \u001b[38;5;28mself\u001b[39m._serialized,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1017\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m missing_prompt_idxs\n\u001b[32m   1018\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Madam\\Shams\\final_shams\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:815\u001b[39m, in \u001b[36mBaseLLM._generate_helper\u001b[39m\u001b[34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[39m\n\u001b[32m    804\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate_helper\u001b[39m(\n\u001b[32m    805\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    806\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    811\u001b[39m     **kwargs: Any,\n\u001b[32m    812\u001b[39m ) -> LLMResult:\n\u001b[32m    813\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    814\u001b[39m         output = (\n\u001b[32m--> \u001b[39m\u001b[32m815\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    816\u001b[39m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    817\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    818\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[32m    819\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    820\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    821\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    822\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    823\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate(prompts, stop=stop)\n\u001b[32m    824\u001b[39m         )\n\u001b[32m    825\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    826\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Madam\\Shams\\final_shams\\.venv\\Lib\\site-packages\\langchain_community\\llms\\ollama.py:437\u001b[39m, in \u001b[36mOllama._generate\u001b[39m\u001b[34m(self, prompts, stop, images, run_manager, **kwargs)\u001b[39m\n\u001b[32m    435\u001b[39m generations = []\n\u001b[32m    436\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[32m--> \u001b[39m\u001b[32m437\u001b[39m     final_chunk = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_stream_with_aggregation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    445\u001b[39m     generations.append([final_chunk])\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations=generations)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Madam\\Shams\\final_shams\\.venv\\Lib\\site-packages\\langchain_community\\llms\\ollama.py:349\u001b[39m, in \u001b[36m_OllamaCommon._stream_with_aggregation\u001b[39m\u001b[34m(self, prompt, stop, run_manager, verbose, **kwargs)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_stream_with_aggregation\u001b[39m(\n\u001b[32m    341\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    342\u001b[39m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    346\u001b[39m     **kwargs: Any,\n\u001b[32m    347\u001b[39m ) -> GenerationChunk:\n\u001b[32m    348\u001b[39m     final_chunk: Optional[GenerationChunk] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m349\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_generate_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m            \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stream_response_to_generation_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Madam\\Shams\\final_shams\\.venv\\Lib\\site-packages\\langchain_community\\llms\\ollama.py:194\u001b[39m, in \u001b[36m_OllamaCommon._create_generate_stream\u001b[39m\u001b[34m(self, prompt, stop, images, **kwargs)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_create_generate_stream\u001b[39m(\n\u001b[32m    187\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    188\u001b[39m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    191\u001b[39m     **kwargs: Any,\n\u001b[32m    192\u001b[39m ) -> Iterator[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    193\u001b[39m     payload = {\u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m: prompt, \u001b[33m\"\u001b[39m\u001b[33mimages\u001b[39m\u001b[33m\"\u001b[39m: images}\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_stream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapi_url\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/api/generate\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Madam\\Shams\\final_shams\\.venv\\Lib\\site-packages\\langchain_community\\llms\\ollama.py:252\u001b[39m, in \u001b[36m_OllamaCommon._create_stream\u001b[39m\u001b[34m(self, api_url, payload, stop, **kwargs)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    247\u001b[39m     request_payload = {\n\u001b[32m    248\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m: payload.get(\u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    249\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mimages\u001b[39m\u001b[33m\"\u001b[39m: payload.get(\u001b[33m\"\u001b[39m\u001b[33mimages\u001b[39m\u001b[33m\"\u001b[39m, []),\n\u001b[32m    250\u001b[39m         **params,\n\u001b[32m    251\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mContent-Type\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mapplication/json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    263\u001b[39m response.encoding = \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code != \u001b[32m200\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Madam\\Shams\\final_shams\\.venv\\Lib\\site-packages\\requests\\api.py:115\u001b[39m, in \u001b[36mpost\u001b[39m\u001b[34m(url, data, json, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(url, data=\u001b[38;5;28;01mNone\u001b[39;00m, json=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m    104\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    112\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Madam\\Shams\\final_shams\\.venv\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Madam\\Shams\\final_shams\\.venv\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Madam\\Shams\\final_shams\\.venv\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Madam\\Shams\\final_shams\\.venv\\Lib\\site-packages\\requests\\adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    641\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Madam\\Shams\\final_shams\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Madam\\Shams\\final_shams\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:493\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    490\u001b[39m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[32m    491\u001b[39m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n\u001b[32m    492\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[32m    505\u001b[39m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[32m    506\u001b[39m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBrokenPipeError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Madam\\Shams\\final_shams\\.venv\\Lib\\site-packages\\urllib3\\connection.py:494\u001b[39m, in \u001b[36mHTTPConnection.request\u001b[39m\u001b[34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    492\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m header, value \u001b[38;5;129;01min\u001b[39;00m headers.items():\n\u001b[32m    493\u001b[39m     \u001b[38;5;28mself\u001b[39m.putheader(header, value)\n\u001b[32m--> \u001b[39m\u001b[32m494\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[38;5;66;03m# If we're given a body we start sending that in chunks.\u001b[39;00m\n\u001b[32m    497\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:1277\u001b[39m, in \u001b[36mHTTPConnection.endheaders\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1275\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1276\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[32m-> \u001b[39m\u001b[32m1277\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:1037\u001b[39m, in \u001b[36mHTTPConnection._send_output\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1035\u001b[39m msg = \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mself\u001b[39m._buffer)\n\u001b[32m   1036\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._buffer[:]\n\u001b[32m-> \u001b[39m\u001b[32m1037\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1039\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1040\u001b[39m \n\u001b[32m   1041\u001b[39m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n\u001b[32m   1042\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(message_body, \u001b[33m'\u001b[39m\u001b[33mread\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m   1043\u001b[39m         \u001b[38;5;66;03m# Let file-like take precedence over byte-like.  This\u001b[39;00m\n\u001b[32m   1044\u001b[39m         \u001b[38;5;66;03m# is needed to allow the current position of mmap'ed\u001b[39;00m\n\u001b[32m   1045\u001b[39m         \u001b[38;5;66;03m# files to be taken into account.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:975\u001b[39m, in \u001b[36mHTTPConnection.send\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    973\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.sock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    974\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_open:\n\u001b[32m--> \u001b[39m\u001b[32m975\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    976\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    977\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m NotConnected()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Madam\\Shams\\final_shams\\.venv\\Lib\\site-packages\\urllib3\\connection.py:325\u001b[39m, in \u001b[36mHTTPConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m     \u001b[38;5;28mself\u001b[39m.sock = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tunnel_host:\n\u001b[32m    327\u001b[39m         \u001b[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n\u001b[32m    328\u001b[39m         \u001b[38;5;28mself\u001b[39m._has_connected_to_proxy = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Madam\\Shams\\final_shams\\.venv\\Lib\\site-packages\\urllib3\\connection.py:198\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Establish a socket connection and set nodelay settings on it.\u001b[39;00m\n\u001b[32m    194\u001b[39m \n\u001b[32m    195\u001b[39m \u001b[33;03m:return: New socket connection.\u001b[39;00m\n\u001b[32m    196\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     sock = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m socket.gaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m.host, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Madam\\Shams\\final_shams\\.venv\\Lib\\site-packages\\urllib3\\util\\connection.py:81\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, socket_options)\u001b[39m\n\u001b[32m     79\u001b[39m         err = _\n\u001b[32m     80\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m sock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m             \u001b[43msock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socket.py:498\u001b[39m, in \u001b[36msocket.close\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_real_close\u001b[39m(\u001b[38;5;28mself\u001b[39m, _ss=_socket.socket):\n\u001b[32m    495\u001b[39m     \u001b[38;5;66;03m# This function should not reference any globals. See issue #808164.\u001b[39;00m\n\u001b[32m    496\u001b[39m     _ss.close(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m498\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mclose\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    499\u001b[39m     \u001b[38;5;66;03m# This function should not reference any globals. See issue #808164.\u001b[39;00m\n\u001b[32m    500\u001b[39m     \u001b[38;5;28mself\u001b[39m._closed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    501\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._io_refs <= \u001b[32m0\u001b[39m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "import pickle, faiss\n",
    "import numpy as np\n",
    "\n",
    "# Initialize embeddings model and LLM\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "llm = Ollama(model=\"gemma3:4b\")\n",
    "\n",
    "# Load raw chunks\n",
    "with open(\"faiss_layer1/index.pkl\", \"rb\") as f:\n",
    "    raw_store_data = pickle.load(f)\n",
    "raw_docstore = raw_store_data[0]\n",
    "\n",
    "summary_texts = []\n",
    "total_chunks = len(raw_docstore._dict)\n",
    "print(f\"Total chunks to summarize: {total_chunks}\\n\")\n",
    "\n",
    "# Summarize each chunk and show progress\n",
    "for i, doc_id in enumerate(raw_docstore._dict.keys(), start=1):\n",
    "    chunk = raw_docstore._dict[doc_id]  # get the actual text\n",
    "    try:\n",
    "        summary = llm.invoke(\n",
    "            f\"Summarize this chunk factually and do not add any fictional events: {chunk}\"\n",
    "        )\n",
    "        summary_texts.append({\"id\": doc_id, \"text\": summary})\n",
    "        print(f\"✅ Chunk {i}/{total_chunks} summarized. Total summaries so far: {len(summary_texts)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠ Failed chunk {i}/{total_chunks} (ID: {doc_id}): {e}\")\n",
    "        continue\n",
    "\n",
    "# Build FAISS index for summaries\n",
    "summary_vectors = [embedding_model.embed_text(s[\"text\"]) for s in summary_texts]\n",
    "dimension = len(summary_vectors[0])\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(np.array(summary_vectors).astype(\"float32\"))\n",
    "\n",
    "# Save docstore + index mapping\n",
    "docstore = {s[\"id\"]: s[\"text\"] for s in summary_texts}\n",
    "index_to_docstore_id = {i: s[\"id\"] for i, s in enumerate(summary_texts)}\n",
    "\n",
    "with open(\"faiss_layer2/index.pkl\", \"wb\") as f:\n",
    "    pickle.dump([docstore, index_to_docstore_id], f)\n",
    "\n",
    "faiss.write_index(index, \"faiss_layer2/index.faiss\")\n",
    "\n",
    "print(f\"\\n🎉 Summary layer rebuild complete!\")\n",
    "print(f\"Total successful summaries/embeddings: {len(summary_texts)}/{total_chunks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "648e24e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Using device: cuda\n",
      "   GPU: Quadro M1200\n",
      "   Memory: 4.29 GB\n",
      "\n",
      "📂 Loading raw chunks...\n",
      "Total chunks to summarize: 1248\n",
      "\n",
      "✅ Chunk 1/1248 summarized. Total summaries so far: 1\n",
      "✅ Chunk 2/1248 summarized. Total summaries so far: 2\n",
      "✅ Chunk 3/1248 summarized. Total summaries so far: 3\n",
      "✅ Chunk 4/1248 summarized. Total summaries so far: 4\n",
      "✅ Chunk 5/1248 summarized. Total summaries so far: 5\n",
      "✅ Chunk 6/1248 summarized. Total summaries so far: 6\n",
      "✅ Chunk 7/1248 summarized. Total summaries so far: 7\n",
      "✅ Chunk 8/1248 summarized. Total summaries so far: 8\n",
      "✅ Chunk 9/1248 summarized. Total summaries so far: 9\n",
      "✅ Chunk 10/1248 summarized. Total summaries so far: 10\n",
      "✅ Chunk 11/1248 summarized. Total summaries so far: 11\n",
      "✅ Chunk 12/1248 summarized. Total summaries so far: 12\n",
      "✅ Chunk 13/1248 summarized. Total summaries so far: 13\n",
      "✅ Chunk 14/1248 summarized. Total summaries so far: 14\n",
      "✅ Chunk 15/1248 summarized. Total summaries so far: 15\n",
      "✅ Chunk 16/1248 summarized. Total summaries so far: 16\n",
      "✅ Chunk 17/1248 summarized. Total summaries so far: 17\n",
      "✅ Chunk 18/1248 summarized. Total summaries so far: 18\n",
      "✅ Chunk 19/1248 summarized. Total summaries so far: 19\n",
      "✅ Chunk 20/1248 summarized. Total summaries so far: 20\n",
      "✅ Chunk 21/1248 summarized. Total summaries so far: 21\n",
      "✅ Chunk 22/1248 summarized. Total summaries so far: 22\n",
      "✅ Chunk 23/1248 summarized. Total summaries so far: 23\n",
      "✅ Chunk 24/1248 summarized. Total summaries so far: 24\n",
      "✅ Chunk 25/1248 summarized. Total summaries so far: 25\n",
      "✅ Chunk 26/1248 summarized. Total summaries so far: 26\n",
      "✅ Chunk 27/1248 summarized. Total summaries so far: 27\n",
      "✅ Chunk 28/1248 summarized. Total summaries so far: 28\n",
      "✅ Chunk 29/1248 summarized. Total summaries so far: 29\n",
      "✅ Chunk 30/1248 summarized. Total summaries so far: 30\n",
      "✅ Chunk 31/1248 summarized. Total summaries so far: 31\n",
      "✅ Chunk 32/1248 summarized. Total summaries so far: 32\n",
      "✅ Chunk 33/1248 summarized. Total summaries so far: 33\n",
      "✅ Chunk 34/1248 summarized. Total summaries so far: 34\n",
      "✅ Chunk 35/1248 summarized. Total summaries so far: 35\n",
      "✅ Chunk 36/1248 summarized. Total summaries so far: 36\n",
      "✅ Chunk 37/1248 summarized. Total summaries so far: 37\n",
      "✅ Chunk 38/1248 summarized. Total summaries so far: 38\n",
      "✅ Chunk 39/1248 summarized. Total summaries so far: 39\n",
      "✅ Chunk 40/1248 summarized. Total summaries so far: 40\n",
      "✅ Chunk 41/1248 summarized. Total summaries so far: 41\n",
      "✅ Chunk 42/1248 summarized. Total summaries so far: 42\n",
      "✅ Chunk 43/1248 summarized. Total summaries so far: 43\n",
      "✅ Chunk 44/1248 summarized. Total summaries so far: 44\n",
      "✅ Chunk 45/1248 summarized. Total summaries so far: 45\n",
      "✅ Chunk 46/1248 summarized. Total summaries so far: 46\n",
      "✅ Chunk 47/1248 summarized. Total summaries so far: 47\n",
      "✅ Chunk 48/1248 summarized. Total summaries so far: 48\n",
      "✅ Chunk 49/1248 summarized. Total summaries so far: 49\n",
      "✅ Chunk 50/1248 summarized. Total summaries so far: 50\n",
      "✅ Chunk 51/1248 summarized. Total summaries so far: 51\n",
      "✅ Chunk 52/1248 summarized. Total summaries so far: 52\n",
      "✅ Chunk 53/1248 summarized. Total summaries so far: 53\n",
      "✅ Chunk 54/1248 summarized. Total summaries so far: 54\n",
      "✅ Chunk 55/1248 summarized. Total summaries so far: 55\n",
      "✅ Chunk 56/1248 summarized. Total summaries so far: 56\n",
      "✅ Chunk 57/1248 summarized. Total summaries so far: 57\n",
      "✅ Chunk 58/1248 summarized. Total summaries so far: 58\n",
      "✅ Chunk 59/1248 summarized. Total summaries so far: 59\n",
      "✅ Chunk 60/1248 summarized. Total summaries so far: 60\n",
      "✅ Chunk 61/1248 summarized. Total summaries so far: 61\n",
      "✅ Chunk 62/1248 summarized. Total summaries so far: 62\n",
      "✅ Chunk 63/1248 summarized. Total summaries so far: 63\n",
      "✅ Chunk 64/1248 summarized. Total summaries so far: 64\n",
      "✅ Chunk 65/1248 summarized. Total summaries so far: 65\n",
      "✅ Chunk 66/1248 summarized. Total summaries so far: 66\n",
      "✅ Chunk 67/1248 summarized. Total summaries so far: 67\n",
      "✅ Chunk 68/1248 summarized. Total summaries so far: 68\n",
      "✅ Chunk 69/1248 summarized. Total summaries so far: 69\n",
      "✅ Chunk 70/1248 summarized. Total summaries so far: 70\n",
      "✅ Chunk 71/1248 summarized. Total summaries so far: 71\n",
      "✅ Chunk 72/1248 summarized. Total summaries so far: 72\n",
      "✅ Chunk 73/1248 summarized. Total summaries so far: 73\n",
      "✅ Chunk 74/1248 summarized. Total summaries so far: 74\n",
      "✅ Chunk 75/1248 summarized. Total summaries so far: 75\n",
      "✅ Chunk 76/1248 summarized. Total summaries so far: 76\n",
      "✅ Chunk 77/1248 summarized. Total summaries so far: 77\n",
      "✅ Chunk 78/1248 summarized. Total summaries so far: 78\n",
      "✅ Chunk 79/1248 summarized. Total summaries so far: 79\n",
      "✅ Chunk 80/1248 summarized. Total summaries so far: 80\n",
      "✅ Chunk 81/1248 summarized. Total summaries so far: 81\n",
      "✅ Chunk 82/1248 summarized. Total summaries so far: 82\n",
      "✅ Chunk 83/1248 summarized. Total summaries so far: 83\n",
      "✅ Chunk 84/1248 summarized. Total summaries so far: 84\n",
      "✅ Chunk 85/1248 summarized. Total summaries so far: 85\n",
      "✅ Chunk 86/1248 summarized. Total summaries so far: 86\n",
      "✅ Chunk 87/1248 summarized. Total summaries so far: 87\n",
      "✅ Chunk 88/1248 summarized. Total summaries so far: 88\n",
      "✅ Chunk 89/1248 summarized. Total summaries so far: 89\n",
      "✅ Chunk 90/1248 summarized. Total summaries so far: 90\n",
      "✅ Chunk 91/1248 summarized. Total summaries so far: 91\n",
      "✅ Chunk 92/1248 summarized. Total summaries so far: 92\n",
      "✅ Chunk 93/1248 summarized. Total summaries so far: 93\n",
      "✅ Chunk 94/1248 summarized. Total summaries so far: 94\n",
      "✅ Chunk 95/1248 summarized. Total summaries so far: 95\n",
      "✅ Chunk 96/1248 summarized. Total summaries so far: 96\n",
      "✅ Chunk 97/1248 summarized. Total summaries so far: 97\n",
      "✅ Chunk 98/1248 summarized. Total summaries so far: 98\n",
      "✅ Chunk 99/1248 summarized. Total summaries so far: 99\n",
      "✅ Chunk 100/1248 summarized. Total summaries so far: 100\n",
      "✅ Chunk 101/1248 summarized. Total summaries so far: 101\n",
      "✅ Chunk 102/1248 summarized. Total summaries so far: 102\n",
      "✅ Chunk 103/1248 summarized. Total summaries so far: 103\n",
      "✅ Chunk 104/1248 summarized. Total summaries so far: 104\n",
      "✅ Chunk 105/1248 summarized. Total summaries so far: 105\n",
      "✅ Chunk 106/1248 summarized. Total summaries so far: 106\n",
      "✅ Chunk 107/1248 summarized. Total summaries so far: 107\n",
      "✅ Chunk 108/1248 summarized. Total summaries so far: 108\n",
      "✅ Chunk 109/1248 summarized. Total summaries so far: 109\n",
      "✅ Chunk 110/1248 summarized. Total summaries so far: 110\n",
      "✅ Chunk 111/1248 summarized. Total summaries so far: 111\n",
      "✅ Chunk 112/1248 summarized. Total summaries so far: 112\n",
      "✅ Chunk 113/1248 summarized. Total summaries so far: 113\n",
      "✅ Chunk 114/1248 summarized. Total summaries so far: 114\n",
      "✅ Chunk 115/1248 summarized. Total summaries so far: 115\n",
      "✅ Chunk 116/1248 summarized. Total summaries so far: 116\n",
      "✅ Chunk 117/1248 summarized. Total summaries so far: 117\n",
      "✅ Chunk 118/1248 summarized. Total summaries so far: 118\n",
      "✅ Chunk 119/1248 summarized. Total summaries so far: 119\n",
      "✅ Chunk 120/1248 summarized. Total summaries so far: 120\n",
      "✅ Chunk 121/1248 summarized. Total summaries so far: 121\n",
      "✅ Chunk 122/1248 summarized. Total summaries so far: 122\n",
      "✅ Chunk 123/1248 summarized. Total summaries so far: 123\n",
      "✅ Chunk 124/1248 summarized. Total summaries so far: 124\n",
      "✅ Chunk 125/1248 summarized. Total summaries so far: 125\n",
      "✅ Chunk 126/1248 summarized. Total summaries so far: 126\n",
      "✅ Chunk 127/1248 summarized. Total summaries so far: 127\n",
      "✅ Chunk 128/1248 summarized. Total summaries so far: 128\n",
      "✅ Chunk 129/1248 summarized. Total summaries so far: 129\n",
      "✅ Chunk 130/1248 summarized. Total summaries so far: 130\n",
      "✅ Chunk 131/1248 summarized. Total summaries so far: 131\n",
      "✅ Chunk 132/1248 summarized. Total summaries so far: 132\n",
      "✅ Chunk 133/1248 summarized. Total summaries so far: 133\n",
      "✅ Chunk 134/1248 summarized. Total summaries so far: 134\n",
      "✅ Chunk 135/1248 summarized. Total summaries so far: 135\n",
      "✅ Chunk 136/1248 summarized. Total summaries so far: 136\n",
      "✅ Chunk 137/1248 summarized. Total summaries so far: 137\n",
      "✅ Chunk 138/1248 summarized. Total summaries so far: 138\n",
      "✅ Chunk 139/1248 summarized. Total summaries so far: 139\n",
      "✅ Chunk 140/1248 summarized. Total summaries so far: 140\n",
      "✅ Chunk 141/1248 summarized. Total summaries so far: 141\n",
      "✅ Chunk 142/1248 summarized. Total summaries so far: 142\n",
      "✅ Chunk 143/1248 summarized. Total summaries so far: 143\n",
      "✅ Chunk 144/1248 summarized. Total summaries so far: 144\n",
      "✅ Chunk 145/1248 summarized. Total summaries so far: 145\n",
      "✅ Chunk 146/1248 summarized. Total summaries so far: 146\n",
      "✅ Chunk 147/1248 summarized. Total summaries so far: 147\n",
      "✅ Chunk 148/1248 summarized. Total summaries so far: 148\n",
      "✅ Chunk 149/1248 summarized. Total summaries so far: 149\n",
      "✅ Chunk 150/1248 summarized. Total summaries so far: 150\n",
      "✅ Chunk 151/1248 summarized. Total summaries so far: 151\n",
      "✅ Chunk 152/1248 summarized. Total summaries so far: 152\n",
      "✅ Chunk 153/1248 summarized. Total summaries so far: 153\n",
      "✅ Chunk 154/1248 summarized. Total summaries so far: 154\n",
      "✅ Chunk 155/1248 summarized. Total summaries so far: 155\n",
      "✅ Chunk 156/1248 summarized. Total summaries so far: 156\n",
      "✅ Chunk 157/1248 summarized. Total summaries so far: 157\n",
      "✅ Chunk 158/1248 summarized. Total summaries so far: 158\n",
      "✅ Chunk 159/1248 summarized. Total summaries so far: 159\n",
      "✅ Chunk 160/1248 summarized. Total summaries so far: 160\n",
      "✅ Chunk 161/1248 summarized. Total summaries so far: 161\n",
      "✅ Chunk 162/1248 summarized. Total summaries so far: 162\n",
      "✅ Chunk 163/1248 summarized. Total summaries so far: 163\n",
      "✅ Chunk 164/1248 summarized. Total summaries so far: 164\n",
      "✅ Chunk 165/1248 summarized. Total summaries so far: 165\n",
      "✅ Chunk 166/1248 summarized. Total summaries so far: 166\n",
      "✅ Chunk 167/1248 summarized. Total summaries so far: 167\n",
      "✅ Chunk 168/1248 summarized. Total summaries so far: 168\n",
      "✅ Chunk 169/1248 summarized. Total summaries so far: 169\n",
      "✅ Chunk 170/1248 summarized. Total summaries so far: 170\n",
      "✅ Chunk 171/1248 summarized. Total summaries so far: 171\n",
      "✅ Chunk 172/1248 summarized. Total summaries so far: 172\n",
      "✅ Chunk 173/1248 summarized. Total summaries so far: 173\n",
      "✅ Chunk 174/1248 summarized. Total summaries so far: 174\n",
      "✅ Chunk 175/1248 summarized. Total summaries so far: 175\n",
      "✅ Chunk 176/1248 summarized. Total summaries so far: 176\n",
      "✅ Chunk 177/1248 summarized. Total summaries so far: 177\n",
      "✅ Chunk 178/1248 summarized. Total summaries so far: 178\n",
      "✅ Chunk 179/1248 summarized. Total summaries so far: 179\n",
      "✅ Chunk 180/1248 summarized. Total summaries so far: 180\n",
      "✅ Chunk 181/1248 summarized. Total summaries so far: 181\n",
      "✅ Chunk 182/1248 summarized. Total summaries so far: 182\n",
      "✅ Chunk 183/1248 summarized. Total summaries so far: 183\n",
      "✅ Chunk 184/1248 summarized. Total summaries so far: 184\n",
      "✅ Chunk 185/1248 summarized. Total summaries so far: 185\n",
      "✅ Chunk 186/1248 summarized. Total summaries so far: 186\n",
      "✅ Chunk 187/1248 summarized. Total summaries so far: 187\n",
      "✅ Chunk 188/1248 summarized. Total summaries so far: 188\n",
      "✅ Chunk 189/1248 summarized. Total summaries so far: 189\n",
      "✅ Chunk 190/1248 summarized. Total summaries so far: 190\n",
      "✅ Chunk 191/1248 summarized. Total summaries so far: 191\n",
      "✅ Chunk 192/1248 summarized. Total summaries so far: 192\n",
      "✅ Chunk 193/1248 summarized. Total summaries so far: 193\n",
      "✅ Chunk 194/1248 summarized. Total summaries so far: 194\n",
      "✅ Chunk 195/1248 summarized. Total summaries so far: 195\n",
      "✅ Chunk 196/1248 summarized. Total summaries so far: 196\n",
      "✅ Chunk 197/1248 summarized. Total summaries so far: 197\n",
      "✅ Chunk 198/1248 summarized. Total summaries so far: 198\n",
      "✅ Chunk 199/1248 summarized. Total summaries so far: 199\n",
      "✅ Chunk 200/1248 summarized. Total summaries so far: 200\n",
      "✅ Chunk 201/1248 summarized. Total summaries so far: 201\n",
      "✅ Chunk 202/1248 summarized. Total summaries so far: 202\n",
      "✅ Chunk 203/1248 summarized. Total summaries so far: 203\n",
      "✅ Chunk 204/1248 summarized. Total summaries so far: 204\n",
      "✅ Chunk 205/1248 summarized. Total summaries so far: 205\n",
      "✅ Chunk 206/1248 summarized. Total summaries so far: 206\n",
      "✅ Chunk 207/1248 summarized. Total summaries so far: 207\n",
      "✅ Chunk 208/1248 summarized. Total summaries so far: 208\n",
      "✅ Chunk 209/1248 summarized. Total summaries so far: 209\n",
      "✅ Chunk 210/1248 summarized. Total summaries so far: 210\n",
      "✅ Chunk 211/1248 summarized. Total summaries so far: 211\n",
      "✅ Chunk 212/1248 summarized. Total summaries so far: 212\n",
      "✅ Chunk 213/1248 summarized. Total summaries so far: 213\n",
      "✅ Chunk 214/1248 summarized. Total summaries so far: 214\n",
      "✅ Chunk 215/1248 summarized. Total summaries so far: 215\n",
      "✅ Chunk 216/1248 summarized. Total summaries so far: 216\n",
      "✅ Chunk 217/1248 summarized. Total summaries so far: 217\n",
      "✅ Chunk 218/1248 summarized. Total summaries so far: 218\n",
      "✅ Chunk 219/1248 summarized. Total summaries so far: 219\n",
      "✅ Chunk 220/1248 summarized. Total summaries so far: 220\n",
      "✅ Chunk 221/1248 summarized. Total summaries so far: 221\n",
      "✅ Chunk 222/1248 summarized. Total summaries so far: 222\n",
      "✅ Chunk 223/1248 summarized. Total summaries so far: 223\n",
      "✅ Chunk 224/1248 summarized. Total summaries so far: 224\n",
      "✅ Chunk 225/1248 summarized. Total summaries so far: 225\n",
      "✅ Chunk 226/1248 summarized. Total summaries so far: 226\n",
      "✅ Chunk 227/1248 summarized. Total summaries so far: 227\n",
      "✅ Chunk 228/1248 summarized. Total summaries so far: 228\n",
      "✅ Chunk 229/1248 summarized. Total summaries so far: 229\n",
      "✅ Chunk 230/1248 summarized. Total summaries so far: 230\n",
      "✅ Chunk 231/1248 summarized. Total summaries so far: 231\n",
      "✅ Chunk 232/1248 summarized. Total summaries so far: 232\n",
      "✅ Chunk 233/1248 summarized. Total summaries so far: 233\n",
      "✅ Chunk 234/1248 summarized. Total summaries so far: 234\n",
      "✅ Chunk 235/1248 summarized. Total summaries so far: 235\n",
      "✅ Chunk 236/1248 summarized. Total summaries so far: 236\n",
      "✅ Chunk 237/1248 summarized. Total summaries so far: 237\n",
      "✅ Chunk 238/1248 summarized. Total summaries so far: 238\n",
      "✅ Chunk 239/1248 summarized. Total summaries so far: 239\n",
      "✅ Chunk 240/1248 summarized. Total summaries so far: 240\n",
      "✅ Chunk 241/1248 summarized. Total summaries so far: 241\n",
      "✅ Chunk 242/1248 summarized. Total summaries so far: 242\n",
      "✅ Chunk 243/1248 summarized. Total summaries so far: 243\n",
      "✅ Chunk 244/1248 summarized. Total summaries so far: 244\n",
      "✅ Chunk 245/1248 summarized. Total summaries so far: 245\n",
      "✅ Chunk 246/1248 summarized. Total summaries so far: 246\n",
      "✅ Chunk 247/1248 summarized. Total summaries so far: 247\n",
      "✅ Chunk 248/1248 summarized. Total summaries so far: 248\n",
      "✅ Chunk 249/1248 summarized. Total summaries so far: 249\n",
      "✅ Chunk 250/1248 summarized. Total summaries so far: 250\n",
      "✅ Chunk 251/1248 summarized. Total summaries so far: 251\n",
      "✅ Chunk 252/1248 summarized. Total summaries so far: 252\n",
      "✅ Chunk 253/1248 summarized. Total summaries so far: 253\n",
      "✅ Chunk 254/1248 summarized. Total summaries so far: 254\n",
      "✅ Chunk 255/1248 summarized. Total summaries so far: 255\n",
      "✅ Chunk 256/1248 summarized. Total summaries so far: 256\n",
      "✅ Chunk 257/1248 summarized. Total summaries so far: 257\n",
      "✅ Chunk 258/1248 summarized. Total summaries so far: 258\n",
      "✅ Chunk 259/1248 summarized. Total summaries so far: 259\n",
      "✅ Chunk 260/1248 summarized. Total summaries so far: 260\n",
      "✅ Chunk 261/1248 summarized. Total summaries so far: 261\n",
      "✅ Chunk 262/1248 summarized. Total summaries so far: 262\n",
      "✅ Chunk 263/1248 summarized. Total summaries so far: 263\n",
      "✅ Chunk 264/1248 summarized. Total summaries so far: 264\n",
      "✅ Chunk 265/1248 summarized. Total summaries so far: 265\n",
      "✅ Chunk 266/1248 summarized. Total summaries so far: 266\n",
      "✅ Chunk 267/1248 summarized. Total summaries so far: 267\n",
      "✅ Chunk 268/1248 summarized. Total summaries so far: 268\n",
      "✅ Chunk 269/1248 summarized. Total summaries so far: 269\n",
      "✅ Chunk 270/1248 summarized. Total summaries so far: 270\n",
      "✅ Chunk 271/1248 summarized. Total summaries so far: 271\n",
      "✅ Chunk 272/1248 summarized. Total summaries so far: 272\n",
      "✅ Chunk 273/1248 summarized. Total summaries so far: 273\n",
      "✅ Chunk 274/1248 summarized. Total summaries so far: 274\n",
      "✅ Chunk 275/1248 summarized. Total summaries so far: 275\n",
      "✅ Chunk 276/1248 summarized. Total summaries so far: 276\n",
      "✅ Chunk 277/1248 summarized. Total summaries so far: 277\n",
      "✅ Chunk 278/1248 summarized. Total summaries so far: 278\n",
      "✅ Chunk 279/1248 summarized. Total summaries so far: 279\n",
      "✅ Chunk 280/1248 summarized. Total summaries so far: 280\n",
      "✅ Chunk 281/1248 summarized. Total summaries so far: 281\n",
      "✅ Chunk 282/1248 summarized. Total summaries so far: 282\n",
      "✅ Chunk 283/1248 summarized. Total summaries so far: 283\n",
      "✅ Chunk 284/1248 summarized. Total summaries so far: 284\n",
      "✅ Chunk 285/1248 summarized. Total summaries so far: 285\n",
      "✅ Chunk 286/1248 summarized. Total summaries so far: 286\n",
      "✅ Chunk 287/1248 summarized. Total summaries so far: 287\n",
      "✅ Chunk 288/1248 summarized. Total summaries so far: 288\n",
      "✅ Chunk 289/1248 summarized. Total summaries so far: 289\n",
      "✅ Chunk 290/1248 summarized. Total summaries so far: 290\n",
      "✅ Chunk 291/1248 summarized. Total summaries so far: 291\n",
      "✅ Chunk 292/1248 summarized. Total summaries so far: 292\n",
      "✅ Chunk 293/1248 summarized. Total summaries so far: 293\n",
      "✅ Chunk 294/1248 summarized. Total summaries so far: 294\n",
      "✅ Chunk 295/1248 summarized. Total summaries so far: 295\n",
      "✅ Chunk 296/1248 summarized. Total summaries so far: 296\n",
      "✅ Chunk 297/1248 summarized. Total summaries so far: 297\n",
      "✅ Chunk 298/1248 summarized. Total summaries so far: 298\n",
      "✅ Chunk 299/1248 summarized. Total summaries so far: 299\n",
      "✅ Chunk 300/1248 summarized. Total summaries so far: 300\n",
      "✅ Chunk 301/1248 summarized. Total summaries so far: 301\n",
      "✅ Chunk 302/1248 summarized. Total summaries so far: 302\n",
      "✅ Chunk 303/1248 summarized. Total summaries so far: 303\n",
      "✅ Chunk 304/1248 summarized. Total summaries so far: 304\n",
      "✅ Chunk 305/1248 summarized. Total summaries so far: 305\n",
      "✅ Chunk 306/1248 summarized. Total summaries so far: 306\n",
      "✅ Chunk 307/1248 summarized. Total summaries so far: 307\n",
      "✅ Chunk 308/1248 summarized. Total summaries so far: 308\n",
      "✅ Chunk 309/1248 summarized. Total summaries so far: 309\n",
      "✅ Chunk 310/1248 summarized. Total summaries so far: 310\n",
      "✅ Chunk 311/1248 summarized. Total summaries so far: 311\n",
      "✅ Chunk 312/1248 summarized. Total summaries so far: 312\n",
      "✅ Chunk 313/1248 summarized. Total summaries so far: 313\n",
      "✅ Chunk 314/1248 summarized. Total summaries so far: 314\n",
      "✅ Chunk 315/1248 summarized. Total summaries so far: 315\n",
      "✅ Chunk 316/1248 summarized. Total summaries so far: 316\n",
      "✅ Chunk 317/1248 summarized. Total summaries so far: 317\n",
      "✅ Chunk 318/1248 summarized. Total summaries so far: 318\n",
      "✅ Chunk 319/1248 summarized. Total summaries so far: 319\n",
      "✅ Chunk 320/1248 summarized. Total summaries so far: 320\n",
      "✅ Chunk 321/1248 summarized. Total summaries so far: 321\n",
      "✅ Chunk 322/1248 summarized. Total summaries so far: 322\n",
      "✅ Chunk 323/1248 summarized. Total summaries so far: 323\n",
      "✅ Chunk 324/1248 summarized. Total summaries so far: 324\n",
      "✅ Chunk 325/1248 summarized. Total summaries so far: 325\n",
      "✅ Chunk 326/1248 summarized. Total summaries so far: 326\n",
      "✅ Chunk 327/1248 summarized. Total summaries so far: 327\n",
      "✅ Chunk 328/1248 summarized. Total summaries so far: 328\n",
      "✅ Chunk 329/1248 summarized. Total summaries so far: 329\n",
      "✅ Chunk 330/1248 summarized. Total summaries so far: 330\n",
      "✅ Chunk 331/1248 summarized. Total summaries so far: 331\n",
      "✅ Chunk 332/1248 summarized. Total summaries so far: 332\n",
      "✅ Chunk 333/1248 summarized. Total summaries so far: 333\n",
      "✅ Chunk 334/1248 summarized. Total summaries so far: 334\n",
      "✅ Chunk 335/1248 summarized. Total summaries so far: 335\n",
      "✅ Chunk 336/1248 summarized. Total summaries so far: 336\n",
      "✅ Chunk 337/1248 summarized. Total summaries so far: 337\n",
      "✅ Chunk 338/1248 summarized. Total summaries so far: 338\n",
      "✅ Chunk 339/1248 summarized. Total summaries so far: 339\n",
      "✅ Chunk 340/1248 summarized. Total summaries so far: 340\n",
      "✅ Chunk 341/1248 summarized. Total summaries so far: 341\n",
      "✅ Chunk 342/1248 summarized. Total summaries so far: 342\n",
      "✅ Chunk 343/1248 summarized. Total summaries so far: 343\n",
      "✅ Chunk 344/1248 summarized. Total summaries so far: 344\n",
      "✅ Chunk 345/1248 summarized. Total summaries so far: 345\n",
      "✅ Chunk 346/1248 summarized. Total summaries so far: 346\n",
      "✅ Chunk 347/1248 summarized. Total summaries so far: 347\n",
      "✅ Chunk 348/1248 summarized. Total summaries so far: 348\n",
      "✅ Chunk 349/1248 summarized. Total summaries so far: 349\n",
      "✅ Chunk 350/1248 summarized. Total summaries so far: 350\n",
      "✅ Chunk 351/1248 summarized. Total summaries so far: 351\n",
      "✅ Chunk 352/1248 summarized. Total summaries so far: 352\n",
      "✅ Chunk 353/1248 summarized. Total summaries so far: 353\n",
      "✅ Chunk 354/1248 summarized. Total summaries so far: 354\n",
      "✅ Chunk 355/1248 summarized. Total summaries so far: 355\n",
      "✅ Chunk 356/1248 summarized. Total summaries so far: 356\n",
      "✅ Chunk 357/1248 summarized. Total summaries so far: 357\n",
      "✅ Chunk 358/1248 summarized. Total summaries so far: 358\n",
      "✅ Chunk 359/1248 summarized. Total summaries so far: 359\n",
      "✅ Chunk 360/1248 summarized. Total summaries so far: 360\n",
      "✅ Chunk 361/1248 summarized. Total summaries so far: 361\n",
      "✅ Chunk 362/1248 summarized. Total summaries so far: 362\n",
      "✅ Chunk 363/1248 summarized. Total summaries so far: 363\n",
      "✅ Chunk 364/1248 summarized. Total summaries so far: 364\n",
      "✅ Chunk 365/1248 summarized. Total summaries so far: 365\n",
      "✅ Chunk 366/1248 summarized. Total summaries so far: 366\n",
      "✅ Chunk 367/1248 summarized. Total summaries so far: 367\n",
      "✅ Chunk 368/1248 summarized. Total summaries so far: 368\n",
      "✅ Chunk 369/1248 summarized. Total summaries so far: 369\n",
      "✅ Chunk 370/1248 summarized. Total summaries so far: 370\n",
      "✅ Chunk 371/1248 summarized. Total summaries so far: 371\n",
      "✅ Chunk 372/1248 summarized. Total summaries so far: 372\n",
      "✅ Chunk 373/1248 summarized. Total summaries so far: 373\n",
      "✅ Chunk 374/1248 summarized. Total summaries so far: 374\n",
      "✅ Chunk 375/1248 summarized. Total summaries so far: 375\n",
      "✅ Chunk 376/1248 summarized. Total summaries so far: 376\n",
      "✅ Chunk 377/1248 summarized. Total summaries so far: 377\n",
      "✅ Chunk 378/1248 summarized. Total summaries so far: 378\n",
      "✅ Chunk 379/1248 summarized. Total summaries so far: 379\n",
      "✅ Chunk 380/1248 summarized. Total summaries so far: 380\n",
      "✅ Chunk 381/1248 summarized. Total summaries so far: 381\n",
      "✅ Chunk 382/1248 summarized. Total summaries so far: 382\n",
      "✅ Chunk 383/1248 summarized. Total summaries so far: 383\n",
      "✅ Chunk 384/1248 summarized. Total summaries so far: 384\n",
      "✅ Chunk 385/1248 summarized. Total summaries so far: 385\n",
      "✅ Chunk 386/1248 summarized. Total summaries so far: 386\n",
      "✅ Chunk 387/1248 summarized. Total summaries so far: 387\n",
      "✅ Chunk 388/1248 summarized. Total summaries so far: 388\n",
      "✅ Chunk 389/1248 summarized. Total summaries so far: 389\n",
      "✅ Chunk 390/1248 summarized. Total summaries so far: 390\n",
      "✅ Chunk 391/1248 summarized. Total summaries so far: 391\n",
      "✅ Chunk 392/1248 summarized. Total summaries so far: 392\n",
      "✅ Chunk 393/1248 summarized. Total summaries so far: 393\n",
      "✅ Chunk 394/1248 summarized. Total summaries so far: 394\n",
      "✅ Chunk 395/1248 summarized. Total summaries so far: 395\n",
      "✅ Chunk 396/1248 summarized. Total summaries so far: 396\n",
      "✅ Chunk 397/1248 summarized. Total summaries so far: 397\n",
      "✅ Chunk 398/1248 summarized. Total summaries so far: 398\n",
      "✅ Chunk 399/1248 summarized. Total summaries so far: 399\n",
      "✅ Chunk 400/1248 summarized. Total summaries so far: 400\n",
      "✅ Chunk 401/1248 summarized. Total summaries so far: 401\n",
      "✅ Chunk 402/1248 summarized. Total summaries so far: 402\n",
      "✅ Chunk 403/1248 summarized. Total summaries so far: 403\n",
      "✅ Chunk 404/1248 summarized. Total summaries so far: 404\n",
      "✅ Chunk 405/1248 summarized. Total summaries so far: 405\n",
      "✅ Chunk 406/1248 summarized. Total summaries so far: 406\n",
      "✅ Chunk 407/1248 summarized. Total summaries so far: 407\n",
      "✅ Chunk 408/1248 summarized. Total summaries so far: 408\n",
      "✅ Chunk 409/1248 summarized. Total summaries so far: 409\n",
      "✅ Chunk 410/1248 summarized. Total summaries so far: 410\n",
      "✅ Chunk 411/1248 summarized. Total summaries so far: 411\n",
      "✅ Chunk 412/1248 summarized. Total summaries so far: 412\n",
      "✅ Chunk 413/1248 summarized. Total summaries so far: 413\n",
      "✅ Chunk 414/1248 summarized. Total summaries so far: 414\n",
      "✅ Chunk 415/1248 summarized. Total summaries so far: 415\n",
      "✅ Chunk 416/1248 summarized. Total summaries so far: 416\n",
      "✅ Chunk 417/1248 summarized. Total summaries so far: 417\n",
      "✅ Chunk 418/1248 summarized. Total summaries so far: 418\n",
      "✅ Chunk 419/1248 summarized. Total summaries so far: 419\n",
      "✅ Chunk 420/1248 summarized. Total summaries so far: 420\n",
      "✅ Chunk 421/1248 summarized. Total summaries so far: 421\n",
      "✅ Chunk 422/1248 summarized. Total summaries so far: 422\n",
      "✅ Chunk 423/1248 summarized. Total summaries so far: 423\n",
      "✅ Chunk 424/1248 summarized. Total summaries so far: 424\n",
      "✅ Chunk 425/1248 summarized. Total summaries so far: 425\n",
      "✅ Chunk 426/1248 summarized. Total summaries so far: 426\n",
      "✅ Chunk 427/1248 summarized. Total summaries so far: 427\n",
      "✅ Chunk 428/1248 summarized. Total summaries so far: 428\n",
      "✅ Chunk 429/1248 summarized. Total summaries so far: 429\n",
      "✅ Chunk 430/1248 summarized. Total summaries so far: 430\n",
      "✅ Chunk 431/1248 summarized. Total summaries so far: 431\n",
      "✅ Chunk 432/1248 summarized. Total summaries so far: 432\n",
      "✅ Chunk 433/1248 summarized. Total summaries so far: 433\n",
      "✅ Chunk 434/1248 summarized. Total summaries so far: 434\n",
      "✅ Chunk 435/1248 summarized. Total summaries so far: 435\n",
      "✅ Chunk 436/1248 summarized. Total summaries so far: 436\n",
      "✅ Chunk 437/1248 summarized. Total summaries so far: 437\n",
      "✅ Chunk 438/1248 summarized. Total summaries so far: 438\n",
      "✅ Chunk 439/1248 summarized. Total summaries so far: 439\n",
      "✅ Chunk 440/1248 summarized. Total summaries so far: 440\n",
      "✅ Chunk 441/1248 summarized. Total summaries so far: 441\n",
      "✅ Chunk 442/1248 summarized. Total summaries so far: 442\n",
      "✅ Chunk 443/1248 summarized. Total summaries so far: 443\n",
      "✅ Chunk 444/1248 summarized. Total summaries so far: 444\n",
      "✅ Chunk 445/1248 summarized. Total summaries so far: 445\n",
      "✅ Chunk 446/1248 summarized. Total summaries so far: 446\n",
      "✅ Chunk 447/1248 summarized. Total summaries so far: 447\n",
      "✅ Chunk 448/1248 summarized. Total summaries so far: 448\n",
      "✅ Chunk 449/1248 summarized. Total summaries so far: 449\n",
      "✅ Chunk 450/1248 summarized. Total summaries so far: 450\n",
      "✅ Chunk 451/1248 summarized. Total summaries so far: 451\n",
      "✅ Chunk 452/1248 summarized. Total summaries so far: 452\n",
      "✅ Chunk 453/1248 summarized. Total summaries so far: 453\n",
      "✅ Chunk 454/1248 summarized. Total summaries so far: 454\n",
      "✅ Chunk 455/1248 summarized. Total summaries so far: 455\n",
      "✅ Chunk 456/1248 summarized. Total summaries so far: 456\n",
      "✅ Chunk 457/1248 summarized. Total summaries so far: 457\n",
      "✅ Chunk 458/1248 summarized. Total summaries so far: 458\n",
      "✅ Chunk 459/1248 summarized. Total summaries so far: 459\n",
      "✅ Chunk 460/1248 summarized. Total summaries so far: 460\n",
      "✅ Chunk 461/1248 summarized. Total summaries so far: 461\n",
      "✅ Chunk 462/1248 summarized. Total summaries so far: 462\n",
      "✅ Chunk 463/1248 summarized. Total summaries so far: 463\n",
      "✅ Chunk 464/1248 summarized. Total summaries so far: 464\n",
      "✅ Chunk 465/1248 summarized. Total summaries so far: 465\n",
      "✅ Chunk 466/1248 summarized. Total summaries so far: 466\n",
      "✅ Chunk 467/1248 summarized. Total summaries so far: 467\n",
      "✅ Chunk 468/1248 summarized. Total summaries so far: 468\n",
      "✅ Chunk 469/1248 summarized. Total summaries so far: 469\n",
      "✅ Chunk 470/1248 summarized. Total summaries so far: 470\n",
      "✅ Chunk 471/1248 summarized. Total summaries so far: 471\n",
      "✅ Chunk 472/1248 summarized. Total summaries so far: 472\n",
      "✅ Chunk 473/1248 summarized. Total summaries so far: 473\n",
      "✅ Chunk 474/1248 summarized. Total summaries so far: 474\n",
      "✅ Chunk 475/1248 summarized. Total summaries so far: 475\n",
      "✅ Chunk 476/1248 summarized. Total summaries so far: 476\n",
      "✅ Chunk 477/1248 summarized. Total summaries so far: 477\n",
      "✅ Chunk 478/1248 summarized. Total summaries so far: 478\n",
      "✅ Chunk 479/1248 summarized. Total summaries so far: 479\n",
      "✅ Chunk 480/1248 summarized. Total summaries so far: 480\n",
      "✅ Chunk 481/1248 summarized. Total summaries so far: 481\n",
      "✅ Chunk 482/1248 summarized. Total summaries so far: 482\n",
      "✅ Chunk 483/1248 summarized. Total summaries so far: 483\n",
      "✅ Chunk 484/1248 summarized. Total summaries so far: 484\n",
      "✅ Chunk 485/1248 summarized. Total summaries so far: 485\n",
      "✅ Chunk 486/1248 summarized. Total summaries so far: 486\n",
      "✅ Chunk 487/1248 summarized. Total summaries so far: 487\n",
      "✅ Chunk 488/1248 summarized. Total summaries so far: 488\n",
      "✅ Chunk 489/1248 summarized. Total summaries so far: 489\n",
      "✅ Chunk 490/1248 summarized. Total summaries so far: 490\n",
      "✅ Chunk 491/1248 summarized. Total summaries so far: 491\n",
      "✅ Chunk 492/1248 summarized. Total summaries so far: 492\n",
      "✅ Chunk 493/1248 summarized. Total summaries so far: 493\n",
      "✅ Chunk 494/1248 summarized. Total summaries so far: 494\n",
      "✅ Chunk 495/1248 summarized. Total summaries so far: 495\n",
      "✅ Chunk 496/1248 summarized. Total summaries so far: 496\n",
      "✅ Chunk 497/1248 summarized. Total summaries so far: 497\n",
      "✅ Chunk 498/1248 summarized. Total summaries so far: 498\n",
      "✅ Chunk 499/1248 summarized. Total summaries so far: 499\n",
      "✅ Chunk 500/1248 summarized. Total summaries so far: 500\n",
      "✅ Chunk 501/1248 summarized. Total summaries so far: 501\n",
      "✅ Chunk 502/1248 summarized. Total summaries so far: 502\n",
      "✅ Chunk 503/1248 summarized. Total summaries so far: 503\n",
      "✅ Chunk 504/1248 summarized. Total summaries so far: 504\n",
      "✅ Chunk 505/1248 summarized. Total summaries so far: 505\n",
      "✅ Chunk 506/1248 summarized. Total summaries so far: 506\n",
      "✅ Chunk 507/1248 summarized. Total summaries so far: 507\n",
      "✅ Chunk 508/1248 summarized. Total summaries so far: 508\n",
      "✅ Chunk 509/1248 summarized. Total summaries so far: 509\n",
      "✅ Chunk 510/1248 summarized. Total summaries so far: 510\n",
      "✅ Chunk 511/1248 summarized. Total summaries so far: 511\n",
      "✅ Chunk 512/1248 summarized. Total summaries so far: 512\n",
      "✅ Chunk 513/1248 summarized. Total summaries so far: 513\n",
      "✅ Chunk 514/1248 summarized. Total summaries so far: 514\n",
      "✅ Chunk 515/1248 summarized. Total summaries so far: 515\n",
      "✅ Chunk 516/1248 summarized. Total summaries so far: 516\n",
      "✅ Chunk 517/1248 summarized. Total summaries so far: 517\n",
      "✅ Chunk 518/1248 summarized. Total summaries so far: 518\n",
      "✅ Chunk 519/1248 summarized. Total summaries so far: 519\n",
      "✅ Chunk 520/1248 summarized. Total summaries so far: 520\n",
      "✅ Chunk 521/1248 summarized. Total summaries so far: 521\n",
      "✅ Chunk 522/1248 summarized. Total summaries so far: 522\n",
      "✅ Chunk 523/1248 summarized. Total summaries so far: 523\n",
      "✅ Chunk 524/1248 summarized. Total summaries so far: 524\n",
      "✅ Chunk 525/1248 summarized. Total summaries so far: 525\n",
      "✅ Chunk 526/1248 summarized. Total summaries so far: 526\n",
      "✅ Chunk 527/1248 summarized. Total summaries so far: 527\n",
      "✅ Chunk 528/1248 summarized. Total summaries so far: 528\n",
      "✅ Chunk 529/1248 summarized. Total summaries so far: 529\n",
      "✅ Chunk 530/1248 summarized. Total summaries so far: 530\n",
      "✅ Chunk 531/1248 summarized. Total summaries so far: 531\n",
      "✅ Chunk 532/1248 summarized. Total summaries so far: 532\n",
      "✅ Chunk 533/1248 summarized. Total summaries so far: 533\n",
      "✅ Chunk 534/1248 summarized. Total summaries so far: 534\n",
      "✅ Chunk 535/1248 summarized. Total summaries so far: 535\n",
      "✅ Chunk 536/1248 summarized. Total summaries so far: 536\n",
      "✅ Chunk 537/1248 summarized. Total summaries so far: 537\n",
      "✅ Chunk 538/1248 summarized. Total summaries so far: 538\n",
      "✅ Chunk 539/1248 summarized. Total summaries so far: 539\n",
      "✅ Chunk 540/1248 summarized. Total summaries so far: 540\n",
      "✅ Chunk 541/1248 summarized. Total summaries so far: 541\n",
      "✅ Chunk 542/1248 summarized. Total summaries so far: 542\n",
      "✅ Chunk 543/1248 summarized. Total summaries so far: 543\n",
      "✅ Chunk 544/1248 summarized. Total summaries so far: 544\n",
      "✅ Chunk 545/1248 summarized. Total summaries so far: 545\n",
      "✅ Chunk 546/1248 summarized. Total summaries so far: 546\n",
      "✅ Chunk 547/1248 summarized. Total summaries so far: 547\n",
      "✅ Chunk 548/1248 summarized. Total summaries so far: 548\n",
      "✅ Chunk 549/1248 summarized. Total summaries so far: 549\n",
      "✅ Chunk 550/1248 summarized. Total summaries so far: 550\n",
      "✅ Chunk 551/1248 summarized. Total summaries so far: 551\n",
      "✅ Chunk 552/1248 summarized. Total summaries so far: 552\n",
      "✅ Chunk 553/1248 summarized. Total summaries so far: 553\n",
      "✅ Chunk 554/1248 summarized. Total summaries so far: 554\n",
      "✅ Chunk 555/1248 summarized. Total summaries so far: 555\n",
      "✅ Chunk 556/1248 summarized. Total summaries so far: 556\n",
      "✅ Chunk 557/1248 summarized. Total summaries so far: 557\n",
      "✅ Chunk 558/1248 summarized. Total summaries so far: 558\n",
      "✅ Chunk 559/1248 summarized. Total summaries so far: 559\n",
      "✅ Chunk 560/1248 summarized. Total summaries so far: 560\n",
      "✅ Chunk 561/1248 summarized. Total summaries so far: 561\n",
      "✅ Chunk 562/1248 summarized. Total summaries so far: 562\n",
      "✅ Chunk 563/1248 summarized. Total summaries so far: 563\n",
      "✅ Chunk 564/1248 summarized. Total summaries so far: 564\n",
      "✅ Chunk 565/1248 summarized. Total summaries so far: 565\n",
      "✅ Chunk 566/1248 summarized. Total summaries so far: 566\n",
      "✅ Chunk 567/1248 summarized. Total summaries so far: 567\n",
      "✅ Chunk 568/1248 summarized. Total summaries so far: 568\n",
      "✅ Chunk 569/1248 summarized. Total summaries so far: 569\n",
      "✅ Chunk 570/1248 summarized. Total summaries so far: 570\n",
      "✅ Chunk 571/1248 summarized. Total summaries so far: 571\n",
      "✅ Chunk 572/1248 summarized. Total summaries so far: 572\n",
      "✅ Chunk 573/1248 summarized. Total summaries so far: 573\n",
      "✅ Chunk 574/1248 summarized. Total summaries so far: 574\n",
      "✅ Chunk 575/1248 summarized. Total summaries so far: 575\n",
      "✅ Chunk 576/1248 summarized. Total summaries so far: 576\n",
      "✅ Chunk 577/1248 summarized. Total summaries so far: 577\n",
      "✅ Chunk 578/1248 summarized. Total summaries so far: 578\n",
      "✅ Chunk 579/1248 summarized. Total summaries so far: 579\n",
      "✅ Chunk 580/1248 summarized. Total summaries so far: 580\n",
      "✅ Chunk 581/1248 summarized. Total summaries so far: 581\n",
      "✅ Chunk 582/1248 summarized. Total summaries so far: 582\n",
      "✅ Chunk 583/1248 summarized. Total summaries so far: 583\n",
      "✅ Chunk 584/1248 summarized. Total summaries so far: 584\n",
      "✅ Chunk 585/1248 summarized. Total summaries so far: 585\n",
      "✅ Chunk 586/1248 summarized. Total summaries so far: 586\n",
      "✅ Chunk 587/1248 summarized. Total summaries so far: 587\n",
      "✅ Chunk 588/1248 summarized. Total summaries so far: 588\n",
      "✅ Chunk 589/1248 summarized. Total summaries so far: 589\n",
      "✅ Chunk 590/1248 summarized. Total summaries so far: 590\n",
      "✅ Chunk 591/1248 summarized. Total summaries so far: 591\n",
      "✅ Chunk 592/1248 summarized. Total summaries so far: 592\n",
      "✅ Chunk 593/1248 summarized. Total summaries so far: 593\n",
      "✅ Chunk 594/1248 summarized. Total summaries so far: 594\n",
      "✅ Chunk 595/1248 summarized. Total summaries so far: 595\n",
      "✅ Chunk 596/1248 summarized. Total summaries so far: 596\n",
      "✅ Chunk 597/1248 summarized. Total summaries so far: 597\n",
      "✅ Chunk 598/1248 summarized. Total summaries so far: 598\n",
      "✅ Chunk 599/1248 summarized. Total summaries so far: 599\n",
      "✅ Chunk 600/1248 summarized. Total summaries so far: 600\n",
      "✅ Chunk 601/1248 summarized. Total summaries so far: 601\n",
      "✅ Chunk 602/1248 summarized. Total summaries so far: 602\n",
      "✅ Chunk 603/1248 summarized. Total summaries so far: 603\n",
      "✅ Chunk 604/1248 summarized. Total summaries so far: 604\n",
      "✅ Chunk 605/1248 summarized. Total summaries so far: 605\n",
      "✅ Chunk 606/1248 summarized. Total summaries so far: 606\n",
      "✅ Chunk 607/1248 summarized. Total summaries so far: 607\n",
      "✅ Chunk 608/1248 summarized. Total summaries so far: 608\n",
      "✅ Chunk 609/1248 summarized. Total summaries so far: 609\n",
      "✅ Chunk 610/1248 summarized. Total summaries so far: 610\n",
      "✅ Chunk 611/1248 summarized. Total summaries so far: 611\n",
      "✅ Chunk 612/1248 summarized. Total summaries so far: 612\n",
      "✅ Chunk 613/1248 summarized. Total summaries so far: 613\n",
      "✅ Chunk 614/1248 summarized. Total summaries so far: 614\n",
      "✅ Chunk 615/1248 summarized. Total summaries so far: 615\n",
      "✅ Chunk 616/1248 summarized. Total summaries so far: 616\n",
      "✅ Chunk 617/1248 summarized. Total summaries so far: 617\n",
      "✅ Chunk 618/1248 summarized. Total summaries so far: 618\n",
      "✅ Chunk 619/1248 summarized. Total summaries so far: 619\n",
      "✅ Chunk 620/1248 summarized. Total summaries so far: 620\n",
      "✅ Chunk 621/1248 summarized. Total summaries so far: 621\n",
      "✅ Chunk 622/1248 summarized. Total summaries so far: 622\n",
      "✅ Chunk 623/1248 summarized. Total summaries so far: 623\n",
      "✅ Chunk 624/1248 summarized. Total summaries so far: 624\n",
      "✅ Chunk 625/1248 summarized. Total summaries so far: 625\n",
      "✅ Chunk 626/1248 summarized. Total summaries so far: 626\n",
      "✅ Chunk 627/1248 summarized. Total summaries so far: 627\n",
      "✅ Chunk 628/1248 summarized. Total summaries so far: 628\n",
      "✅ Chunk 629/1248 summarized. Total summaries so far: 629\n",
      "✅ Chunk 630/1248 summarized. Total summaries so far: 630\n",
      "✅ Chunk 631/1248 summarized. Total summaries so far: 631\n",
      "✅ Chunk 632/1248 summarized. Total summaries so far: 632\n",
      "✅ Chunk 633/1248 summarized. Total summaries so far: 633\n",
      "✅ Chunk 634/1248 summarized. Total summaries so far: 634\n",
      "✅ Chunk 635/1248 summarized. Total summaries so far: 635\n",
      "✅ Chunk 636/1248 summarized. Total summaries so far: 636\n",
      "✅ Chunk 637/1248 summarized. Total summaries so far: 637\n",
      "✅ Chunk 638/1248 summarized. Total summaries so far: 638\n",
      "✅ Chunk 639/1248 summarized. Total summaries so far: 639\n",
      "✅ Chunk 640/1248 summarized. Total summaries so far: 640\n",
      "✅ Chunk 641/1248 summarized. Total summaries so far: 641\n",
      "✅ Chunk 642/1248 summarized. Total summaries so far: 642\n",
      "✅ Chunk 643/1248 summarized. Total summaries so far: 643\n",
      "✅ Chunk 644/1248 summarized. Total summaries so far: 644\n",
      "✅ Chunk 645/1248 summarized. Total summaries so far: 645\n",
      "✅ Chunk 646/1248 summarized. Total summaries so far: 646\n",
      "✅ Chunk 647/1248 summarized. Total summaries so far: 647\n",
      "✅ Chunk 648/1248 summarized. Total summaries so far: 648\n",
      "✅ Chunk 649/1248 summarized. Total summaries so far: 649\n",
      "✅ Chunk 650/1248 summarized. Total summaries so far: 650\n",
      "✅ Chunk 651/1248 summarized. Total summaries so far: 651\n",
      "✅ Chunk 652/1248 summarized. Total summaries so far: 652\n",
      "✅ Chunk 653/1248 summarized. Total summaries so far: 653\n",
      "✅ Chunk 654/1248 summarized. Total summaries so far: 654\n",
      "✅ Chunk 655/1248 summarized. Total summaries so far: 655\n",
      "✅ Chunk 656/1248 summarized. Total summaries so far: 656\n",
      "✅ Chunk 657/1248 summarized. Total summaries so far: 657\n",
      "✅ Chunk 658/1248 summarized. Total summaries so far: 658\n",
      "✅ Chunk 659/1248 summarized. Total summaries so far: 659\n",
      "✅ Chunk 660/1248 summarized. Total summaries so far: 660\n",
      "✅ Chunk 661/1248 summarized. Total summaries so far: 661\n",
      "✅ Chunk 662/1248 summarized. Total summaries so far: 662\n",
      "✅ Chunk 663/1248 summarized. Total summaries so far: 663\n",
      "✅ Chunk 664/1248 summarized. Total summaries so far: 664\n",
      "✅ Chunk 665/1248 summarized. Total summaries so far: 665\n",
      "✅ Chunk 666/1248 summarized. Total summaries so far: 666\n",
      "✅ Chunk 667/1248 summarized. Total summaries so far: 667\n",
      "✅ Chunk 668/1248 summarized. Total summaries so far: 668\n",
      "✅ Chunk 669/1248 summarized. Total summaries so far: 669\n",
      "✅ Chunk 670/1248 summarized. Total summaries so far: 670\n",
      "✅ Chunk 671/1248 summarized. Total summaries so far: 671\n",
      "✅ Chunk 672/1248 summarized. Total summaries so far: 672\n",
      "✅ Chunk 673/1248 summarized. Total summaries so far: 673\n",
      "✅ Chunk 674/1248 summarized. Total summaries so far: 674\n",
      "✅ Chunk 675/1248 summarized. Total summaries so far: 675\n",
      "✅ Chunk 676/1248 summarized. Total summaries so far: 676\n",
      "✅ Chunk 677/1248 summarized. Total summaries so far: 677\n",
      "✅ Chunk 678/1248 summarized. Total summaries so far: 678\n",
      "✅ Chunk 679/1248 summarized. Total summaries so far: 679\n",
      "✅ Chunk 680/1248 summarized. Total summaries so far: 680\n",
      "✅ Chunk 681/1248 summarized. Total summaries so far: 681\n",
      "✅ Chunk 682/1248 summarized. Total summaries so far: 682\n",
      "✅ Chunk 683/1248 summarized. Total summaries so far: 683\n",
      "✅ Chunk 684/1248 summarized. Total summaries so far: 684\n",
      "✅ Chunk 685/1248 summarized. Total summaries so far: 685\n",
      "✅ Chunk 686/1248 summarized. Total summaries so far: 686\n",
      "✅ Chunk 687/1248 summarized. Total summaries so far: 687\n",
      "✅ Chunk 688/1248 summarized. Total summaries so far: 688\n",
      "✅ Chunk 689/1248 summarized. Total summaries so far: 689\n",
      "✅ Chunk 690/1248 summarized. Total summaries so far: 690\n",
      "✅ Chunk 691/1248 summarized. Total summaries so far: 691\n",
      "✅ Chunk 692/1248 summarized. Total summaries so far: 692\n",
      "✅ Chunk 693/1248 summarized. Total summaries so far: 693\n",
      "✅ Chunk 694/1248 summarized. Total summaries so far: 694\n",
      "✅ Chunk 695/1248 summarized. Total summaries so far: 695\n",
      "✅ Chunk 696/1248 summarized. Total summaries so far: 696\n",
      "✅ Chunk 697/1248 summarized. Total summaries so far: 697\n",
      "✅ Chunk 698/1248 summarized. Total summaries so far: 698\n",
      "✅ Chunk 699/1248 summarized. Total summaries so far: 699\n",
      "✅ Chunk 700/1248 summarized. Total summaries so far: 700\n",
      "✅ Chunk 701/1248 summarized. Total summaries so far: 701\n",
      "✅ Chunk 702/1248 summarized. Total summaries so far: 702\n",
      "✅ Chunk 703/1248 summarized. Total summaries so far: 703\n",
      "✅ Chunk 704/1248 summarized. Total summaries so far: 704\n",
      "✅ Chunk 705/1248 summarized. Total summaries so far: 705\n",
      "✅ Chunk 706/1248 summarized. Total summaries so far: 706\n",
      "✅ Chunk 707/1248 summarized. Total summaries so far: 707\n",
      "✅ Chunk 708/1248 summarized. Total summaries so far: 708\n",
      "✅ Chunk 709/1248 summarized. Total summaries so far: 709\n",
      "✅ Chunk 710/1248 summarized. Total summaries so far: 710\n",
      "✅ Chunk 711/1248 summarized. Total summaries so far: 711\n",
      "✅ Chunk 712/1248 summarized. Total summaries so far: 712\n",
      "✅ Chunk 713/1248 summarized. Total summaries so far: 713\n",
      "✅ Chunk 714/1248 summarized. Total summaries so far: 714\n",
      "✅ Chunk 715/1248 summarized. Total summaries so far: 715\n",
      "✅ Chunk 716/1248 summarized. Total summaries so far: 716\n",
      "✅ Chunk 717/1248 summarized. Total summaries so far: 717\n",
      "✅ Chunk 718/1248 summarized. Total summaries so far: 718\n",
      "✅ Chunk 719/1248 summarized. Total summaries so far: 719\n",
      "✅ Chunk 720/1248 summarized. Total summaries so far: 720\n",
      "✅ Chunk 721/1248 summarized. Total summaries so far: 721\n",
      "✅ Chunk 722/1248 summarized. Total summaries so far: 722\n",
      "✅ Chunk 723/1248 summarized. Total summaries so far: 723\n",
      "✅ Chunk 724/1248 summarized. Total summaries so far: 724\n",
      "✅ Chunk 725/1248 summarized. Total summaries so far: 725\n",
      "✅ Chunk 726/1248 summarized. Total summaries so far: 726\n",
      "✅ Chunk 727/1248 summarized. Total summaries so far: 727\n",
      "✅ Chunk 728/1248 summarized. Total summaries so far: 728\n",
      "✅ Chunk 729/1248 summarized. Total summaries so far: 729\n",
      "✅ Chunk 730/1248 summarized. Total summaries so far: 730\n",
      "✅ Chunk 731/1248 summarized. Total summaries so far: 731\n",
      "✅ Chunk 732/1248 summarized. Total summaries so far: 732\n",
      "✅ Chunk 733/1248 summarized. Total summaries so far: 733\n",
      "✅ Chunk 734/1248 summarized. Total summaries so far: 734\n",
      "✅ Chunk 735/1248 summarized. Total summaries so far: 735\n",
      "✅ Chunk 736/1248 summarized. Total summaries so far: 736\n",
      "✅ Chunk 737/1248 summarized. Total summaries so far: 737\n",
      "✅ Chunk 738/1248 summarized. Total summaries so far: 738\n",
      "✅ Chunk 739/1248 summarized. Total summaries so far: 739\n",
      "✅ Chunk 740/1248 summarized. Total summaries so far: 740\n",
      "✅ Chunk 741/1248 summarized. Total summaries so far: 741\n",
      "✅ Chunk 742/1248 summarized. Total summaries so far: 742\n",
      "✅ Chunk 743/1248 summarized. Total summaries so far: 743\n",
      "✅ Chunk 744/1248 summarized. Total summaries so far: 744\n",
      "✅ Chunk 745/1248 summarized. Total summaries so far: 745\n",
      "✅ Chunk 746/1248 summarized. Total summaries so far: 746\n",
      "✅ Chunk 747/1248 summarized. Total summaries so far: 747\n",
      "✅ Chunk 748/1248 summarized. Total summaries so far: 748\n",
      "✅ Chunk 749/1248 summarized. Total summaries so far: 749\n",
      "✅ Chunk 750/1248 summarized. Total summaries so far: 750\n",
      "✅ Chunk 751/1248 summarized. Total summaries so far: 751\n",
      "✅ Chunk 752/1248 summarized. Total summaries so far: 752\n",
      "✅ Chunk 753/1248 summarized. Total summaries so far: 753\n",
      "✅ Chunk 754/1248 summarized. Total summaries so far: 754\n",
      "✅ Chunk 755/1248 summarized. Total summaries so far: 755\n",
      "✅ Chunk 756/1248 summarized. Total summaries so far: 756\n",
      "✅ Chunk 757/1248 summarized. Total summaries so far: 757\n",
      "✅ Chunk 758/1248 summarized. Total summaries so far: 758\n",
      "✅ Chunk 759/1248 summarized. Total summaries so far: 759\n",
      "✅ Chunk 760/1248 summarized. Total summaries so far: 760\n",
      "✅ Chunk 761/1248 summarized. Total summaries so far: 761\n",
      "✅ Chunk 762/1248 summarized. Total summaries so far: 762\n",
      "✅ Chunk 763/1248 summarized. Total summaries so far: 763\n",
      "✅ Chunk 764/1248 summarized. Total summaries so far: 764\n",
      "✅ Chunk 765/1248 summarized. Total summaries so far: 765\n",
      "✅ Chunk 766/1248 summarized. Total summaries so far: 766\n",
      "✅ Chunk 767/1248 summarized. Total summaries so far: 767\n",
      "✅ Chunk 768/1248 summarized. Total summaries so far: 768\n",
      "✅ Chunk 769/1248 summarized. Total summaries so far: 769\n",
      "✅ Chunk 770/1248 summarized. Total summaries so far: 770\n",
      "✅ Chunk 771/1248 summarized. Total summaries so far: 771\n",
      "✅ Chunk 772/1248 summarized. Total summaries so far: 772\n",
      "✅ Chunk 773/1248 summarized. Total summaries so far: 773\n",
      "✅ Chunk 774/1248 summarized. Total summaries so far: 774\n",
      "✅ Chunk 775/1248 summarized. Total summaries so far: 775\n",
      "✅ Chunk 776/1248 summarized. Total summaries so far: 776\n",
      "✅ Chunk 777/1248 summarized. Total summaries so far: 777\n",
      "✅ Chunk 778/1248 summarized. Total summaries so far: 778\n",
      "✅ Chunk 779/1248 summarized. Total summaries so far: 779\n",
      "✅ Chunk 780/1248 summarized. Total summaries so far: 780\n",
      "✅ Chunk 781/1248 summarized. Total summaries so far: 781\n",
      "✅ Chunk 782/1248 summarized. Total summaries so far: 782\n",
      "✅ Chunk 783/1248 summarized. Total summaries so far: 783\n",
      "✅ Chunk 784/1248 summarized. Total summaries so far: 784\n",
      "✅ Chunk 785/1248 summarized. Total summaries so far: 785\n",
      "✅ Chunk 786/1248 summarized. Total summaries so far: 786\n",
      "✅ Chunk 787/1248 summarized. Total summaries so far: 787\n",
      "✅ Chunk 788/1248 summarized. Total summaries so far: 788\n",
      "✅ Chunk 789/1248 summarized. Total summaries so far: 789\n",
      "✅ Chunk 790/1248 summarized. Total summaries so far: 790\n",
      "✅ Chunk 791/1248 summarized. Total summaries so far: 791\n",
      "✅ Chunk 792/1248 summarized. Total summaries so far: 792\n",
      "✅ Chunk 793/1248 summarized. Total summaries so far: 793\n",
      "✅ Chunk 794/1248 summarized. Total summaries so far: 794\n",
      "✅ Chunk 795/1248 summarized. Total summaries so far: 795\n",
      "✅ Chunk 796/1248 summarized. Total summaries so far: 796\n",
      "✅ Chunk 797/1248 summarized. Total summaries so far: 797\n",
      "✅ Chunk 798/1248 summarized. Total summaries so far: 798\n",
      "✅ Chunk 799/1248 summarized. Total summaries so far: 799\n",
      "✅ Chunk 800/1248 summarized. Total summaries so far: 800\n",
      "✅ Chunk 801/1248 summarized. Total summaries so far: 801\n",
      "✅ Chunk 802/1248 summarized. Total summaries so far: 802\n",
      "✅ Chunk 803/1248 summarized. Total summaries so far: 803\n",
      "✅ Chunk 804/1248 summarized. Total summaries so far: 804\n",
      "✅ Chunk 805/1248 summarized. Total summaries so far: 805\n",
      "✅ Chunk 806/1248 summarized. Total summaries so far: 806\n",
      "✅ Chunk 807/1248 summarized. Total summaries so far: 807\n",
      "✅ Chunk 808/1248 summarized. Total summaries so far: 808\n",
      "✅ Chunk 809/1248 summarized. Total summaries so far: 809\n",
      "✅ Chunk 810/1248 summarized. Total summaries so far: 810\n",
      "✅ Chunk 811/1248 summarized. Total summaries so far: 811\n",
      "✅ Chunk 812/1248 summarized. Total summaries so far: 812\n",
      "✅ Chunk 813/1248 summarized. Total summaries so far: 813\n",
      "✅ Chunk 814/1248 summarized. Total summaries so far: 814\n",
      "✅ Chunk 815/1248 summarized. Total summaries so far: 815\n",
      "✅ Chunk 816/1248 summarized. Total summaries so far: 816\n",
      "✅ Chunk 817/1248 summarized. Total summaries so far: 817\n",
      "✅ Chunk 818/1248 summarized. Total summaries so far: 818\n",
      "✅ Chunk 819/1248 summarized. Total summaries so far: 819\n",
      "✅ Chunk 820/1248 summarized. Total summaries so far: 820\n",
      "✅ Chunk 821/1248 summarized. Total summaries so far: 821\n",
      "✅ Chunk 822/1248 summarized. Total summaries so far: 822\n",
      "✅ Chunk 823/1248 summarized. Total summaries so far: 823\n",
      "✅ Chunk 824/1248 summarized. Total summaries so far: 824\n",
      "✅ Chunk 825/1248 summarized. Total summaries so far: 825\n",
      "✅ Chunk 826/1248 summarized. Total summaries so far: 826\n",
      "✅ Chunk 827/1248 summarized. Total summaries so far: 827\n",
      "✅ Chunk 828/1248 summarized. Total summaries so far: 828\n",
      "✅ Chunk 829/1248 summarized. Total summaries so far: 829\n",
      "✅ Chunk 830/1248 summarized. Total summaries so far: 830\n",
      "✅ Chunk 831/1248 summarized. Total summaries so far: 831\n",
      "✅ Chunk 832/1248 summarized. Total summaries so far: 832\n",
      "✅ Chunk 833/1248 summarized. Total summaries so far: 833\n",
      "✅ Chunk 834/1248 summarized. Total summaries so far: 834\n",
      "✅ Chunk 835/1248 summarized. Total summaries so far: 835\n",
      "✅ Chunk 836/1248 summarized. Total summaries so far: 836\n",
      "✅ Chunk 837/1248 summarized. Total summaries so far: 837\n",
      "✅ Chunk 838/1248 summarized. Total summaries so far: 838\n",
      "✅ Chunk 839/1248 summarized. Total summaries so far: 839\n",
      "✅ Chunk 840/1248 summarized. Total summaries so far: 840\n",
      "✅ Chunk 841/1248 summarized. Total summaries so far: 841\n",
      "✅ Chunk 842/1248 summarized. Total summaries so far: 842\n",
      "✅ Chunk 843/1248 summarized. Total summaries so far: 843\n",
      "✅ Chunk 844/1248 summarized. Total summaries so far: 844\n",
      "✅ Chunk 845/1248 summarized. Total summaries so far: 845\n",
      "✅ Chunk 846/1248 summarized. Total summaries so far: 846\n",
      "✅ Chunk 847/1248 summarized. Total summaries so far: 847\n",
      "✅ Chunk 848/1248 summarized. Total summaries so far: 848\n",
      "✅ Chunk 849/1248 summarized. Total summaries so far: 849\n",
      "✅ Chunk 850/1248 summarized. Total summaries so far: 850\n",
      "✅ Chunk 851/1248 summarized. Total summaries so far: 851\n",
      "✅ Chunk 852/1248 summarized. Total summaries so far: 852\n",
      "✅ Chunk 853/1248 summarized. Total summaries so far: 853\n",
      "✅ Chunk 854/1248 summarized. Total summaries so far: 854\n",
      "✅ Chunk 855/1248 summarized. Total summaries so far: 855\n",
      "✅ Chunk 856/1248 summarized. Total summaries so far: 856\n",
      "✅ Chunk 857/1248 summarized. Total summaries so far: 857\n",
      "✅ Chunk 858/1248 summarized. Total summaries so far: 858\n",
      "✅ Chunk 859/1248 summarized. Total summaries so far: 859\n",
      "✅ Chunk 860/1248 summarized. Total summaries so far: 860\n",
      "✅ Chunk 861/1248 summarized. Total summaries so far: 861\n",
      "✅ Chunk 862/1248 summarized. Total summaries so far: 862\n",
      "✅ Chunk 863/1248 summarized. Total summaries so far: 863\n",
      "✅ Chunk 864/1248 summarized. Total summaries so far: 864\n",
      "✅ Chunk 865/1248 summarized. Total summaries so far: 865\n",
      "✅ Chunk 866/1248 summarized. Total summaries so far: 866\n",
      "✅ Chunk 867/1248 summarized. Total summaries so far: 867\n",
      "✅ Chunk 868/1248 summarized. Total summaries so far: 868\n",
      "✅ Chunk 869/1248 summarized. Total summaries so far: 869\n",
      "✅ Chunk 870/1248 summarized. Total summaries so far: 870\n",
      "✅ Chunk 871/1248 summarized. Total summaries so far: 871\n",
      "✅ Chunk 872/1248 summarized. Total summaries so far: 872\n",
      "✅ Chunk 873/1248 summarized. Total summaries so far: 873\n",
      "✅ Chunk 874/1248 summarized. Total summaries so far: 874\n",
      "✅ Chunk 875/1248 summarized. Total summaries so far: 875\n",
      "✅ Chunk 876/1248 summarized. Total summaries so far: 876\n",
      "✅ Chunk 877/1248 summarized. Total summaries so far: 877\n",
      "✅ Chunk 878/1248 summarized. Total summaries so far: 878\n",
      "✅ Chunk 879/1248 summarized. Total summaries so far: 879\n",
      "✅ Chunk 880/1248 summarized. Total summaries so far: 880\n",
      "✅ Chunk 881/1248 summarized. Total summaries so far: 881\n",
      "✅ Chunk 882/1248 summarized. Total summaries so far: 882\n",
      "✅ Chunk 883/1248 summarized. Total summaries so far: 883\n",
      "✅ Chunk 884/1248 summarized. Total summaries so far: 884\n",
      "✅ Chunk 885/1248 summarized. Total summaries so far: 885\n",
      "✅ Chunk 886/1248 summarized. Total summaries so far: 886\n",
      "✅ Chunk 887/1248 summarized. Total summaries so far: 887\n",
      "✅ Chunk 888/1248 summarized. Total summaries so far: 888\n",
      "✅ Chunk 889/1248 summarized. Total summaries so far: 889\n",
      "✅ Chunk 890/1248 summarized. Total summaries so far: 890\n",
      "✅ Chunk 891/1248 summarized. Total summaries so far: 891\n",
      "✅ Chunk 892/1248 summarized. Total summaries so far: 892\n",
      "✅ Chunk 893/1248 summarized. Total summaries so far: 893\n",
      "✅ Chunk 894/1248 summarized. Total summaries so far: 894\n",
      "✅ Chunk 895/1248 summarized. Total summaries so far: 895\n",
      "✅ Chunk 896/1248 summarized. Total summaries so far: 896\n",
      "✅ Chunk 897/1248 summarized. Total summaries so far: 897\n",
      "✅ Chunk 898/1248 summarized. Total summaries so far: 898\n",
      "✅ Chunk 899/1248 summarized. Total summaries so far: 899\n",
      "✅ Chunk 900/1248 summarized. Total summaries so far: 900\n",
      "✅ Chunk 901/1248 summarized. Total summaries so far: 901\n",
      "✅ Chunk 902/1248 summarized. Total summaries so far: 902\n",
      "✅ Chunk 903/1248 summarized. Total summaries so far: 903\n",
      "✅ Chunk 904/1248 summarized. Total summaries so far: 904\n",
      "✅ Chunk 905/1248 summarized. Total summaries so far: 905\n",
      "✅ Chunk 906/1248 summarized. Total summaries so far: 906\n",
      "✅ Chunk 907/1248 summarized. Total summaries so far: 907\n",
      "✅ Chunk 908/1248 summarized. Total summaries so far: 908\n",
      "✅ Chunk 909/1248 summarized. Total summaries so far: 909\n",
      "✅ Chunk 910/1248 summarized. Total summaries so far: 910\n",
      "✅ Chunk 911/1248 summarized. Total summaries so far: 911\n",
      "✅ Chunk 912/1248 summarized. Total summaries so far: 912\n",
      "✅ Chunk 913/1248 summarized. Total summaries so far: 913\n",
      "✅ Chunk 914/1248 summarized. Total summaries so far: 914\n",
      "✅ Chunk 915/1248 summarized. Total summaries so far: 915\n",
      "✅ Chunk 916/1248 summarized. Total summaries so far: 916\n",
      "✅ Chunk 917/1248 summarized. Total summaries so far: 917\n",
      "✅ Chunk 918/1248 summarized. Total summaries so far: 918\n",
      "✅ Chunk 919/1248 summarized. Total summaries so far: 919\n",
      "✅ Chunk 920/1248 summarized. Total summaries so far: 920\n",
      "✅ Chunk 921/1248 summarized. Total summaries so far: 921\n",
      "✅ Chunk 922/1248 summarized. Total summaries so far: 922\n",
      "✅ Chunk 923/1248 summarized. Total summaries so far: 923\n",
      "✅ Chunk 924/1248 summarized. Total summaries so far: 924\n",
      "✅ Chunk 925/1248 summarized. Total summaries so far: 925\n",
      "✅ Chunk 926/1248 summarized. Total summaries so far: 926\n",
      "✅ Chunk 927/1248 summarized. Total summaries so far: 927\n",
      "✅ Chunk 928/1248 summarized. Total summaries so far: 928\n",
      "✅ Chunk 929/1248 summarized. Total summaries so far: 929\n",
      "✅ Chunk 930/1248 summarized. Total summaries so far: 930\n",
      "✅ Chunk 931/1248 summarized. Total summaries so far: 931\n",
      "✅ Chunk 932/1248 summarized. Total summaries so far: 932\n",
      "✅ Chunk 933/1248 summarized. Total summaries so far: 933\n",
      "✅ Chunk 934/1248 summarized. Total summaries so far: 934\n",
      "✅ Chunk 935/1248 summarized. Total summaries so far: 935\n",
      "✅ Chunk 936/1248 summarized. Total summaries so far: 936\n",
      "✅ Chunk 937/1248 summarized. Total summaries so far: 937\n",
      "✅ Chunk 938/1248 summarized. Total summaries so far: 938\n",
      "✅ Chunk 939/1248 summarized. Total summaries so far: 939\n",
      "✅ Chunk 940/1248 summarized. Total summaries so far: 940\n",
      "✅ Chunk 941/1248 summarized. Total summaries so far: 941\n",
      "✅ Chunk 942/1248 summarized. Total summaries so far: 942\n",
      "✅ Chunk 943/1248 summarized. Total summaries so far: 943\n",
      "✅ Chunk 944/1248 summarized. Total summaries so far: 944\n",
      "✅ Chunk 945/1248 summarized. Total summaries so far: 945\n",
      "✅ Chunk 946/1248 summarized. Total summaries so far: 946\n",
      "✅ Chunk 947/1248 summarized. Total summaries so far: 947\n",
      "✅ Chunk 948/1248 summarized. Total summaries so far: 948\n",
      "✅ Chunk 949/1248 summarized. Total summaries so far: 949\n",
      "✅ Chunk 950/1248 summarized. Total summaries so far: 950\n",
      "✅ Chunk 951/1248 summarized. Total summaries so far: 951\n",
      "✅ Chunk 952/1248 summarized. Total summaries so far: 952\n",
      "✅ Chunk 953/1248 summarized. Total summaries so far: 953\n",
      "✅ Chunk 954/1248 summarized. Total summaries so far: 954\n",
      "✅ Chunk 955/1248 summarized. Total summaries so far: 955\n",
      "✅ Chunk 956/1248 summarized. Total summaries so far: 956\n",
      "✅ Chunk 957/1248 summarized. Total summaries so far: 957\n",
      "✅ Chunk 958/1248 summarized. Total summaries so far: 958\n",
      "✅ Chunk 959/1248 summarized. Total summaries so far: 959\n",
      "✅ Chunk 960/1248 summarized. Total summaries so far: 960\n",
      "✅ Chunk 961/1248 summarized. Total summaries so far: 961\n",
      "✅ Chunk 962/1248 summarized. Total summaries so far: 962\n",
      "✅ Chunk 963/1248 summarized. Total summaries so far: 963\n",
      "✅ Chunk 964/1248 summarized. Total summaries so far: 964\n",
      "✅ Chunk 965/1248 summarized. Total summaries so far: 965\n",
      "✅ Chunk 966/1248 summarized. Total summaries so far: 966\n",
      "✅ Chunk 967/1248 summarized. Total summaries so far: 967\n",
      "✅ Chunk 968/1248 summarized. Total summaries so far: 968\n",
      "✅ Chunk 969/1248 summarized. Total summaries so far: 969\n",
      "✅ Chunk 970/1248 summarized. Total summaries so far: 970\n",
      "✅ Chunk 971/1248 summarized. Total summaries so far: 971\n",
      "✅ Chunk 972/1248 summarized. Total summaries so far: 972\n",
      "✅ Chunk 973/1248 summarized. Total summaries so far: 973\n",
      "✅ Chunk 974/1248 summarized. Total summaries so far: 974\n",
      "✅ Chunk 975/1248 summarized. Total summaries so far: 975\n",
      "✅ Chunk 976/1248 summarized. Total summaries so far: 976\n",
      "✅ Chunk 977/1248 summarized. Total summaries so far: 977\n",
      "✅ Chunk 978/1248 summarized. Total summaries so far: 978\n",
      "✅ Chunk 979/1248 summarized. Total summaries so far: 979\n",
      "✅ Chunk 980/1248 summarized. Total summaries so far: 980\n",
      "✅ Chunk 981/1248 summarized. Total summaries so far: 981\n",
      "✅ Chunk 982/1248 summarized. Total summaries so far: 982\n",
      "✅ Chunk 983/1248 summarized. Total summaries so far: 983\n",
      "✅ Chunk 984/1248 summarized. Total summaries so far: 984\n",
      "✅ Chunk 985/1248 summarized. Total summaries so far: 985\n",
      "✅ Chunk 986/1248 summarized. Total summaries so far: 986\n",
      "✅ Chunk 987/1248 summarized. Total summaries so far: 987\n",
      "✅ Chunk 988/1248 summarized. Total summaries so far: 988\n",
      "✅ Chunk 989/1248 summarized. Total summaries so far: 989\n",
      "✅ Chunk 990/1248 summarized. Total summaries so far: 990\n",
      "✅ Chunk 991/1248 summarized. Total summaries so far: 991\n",
      "✅ Chunk 992/1248 summarized. Total summaries so far: 992\n",
      "✅ Chunk 993/1248 summarized. Total summaries so far: 993\n",
      "✅ Chunk 994/1248 summarized. Total summaries so far: 994\n",
      "✅ Chunk 995/1248 summarized. Total summaries so far: 995\n",
      "✅ Chunk 996/1248 summarized. Total summaries so far: 996\n",
      "✅ Chunk 997/1248 summarized. Total summaries so far: 997\n",
      "✅ Chunk 998/1248 summarized. Total summaries so far: 998\n",
      "✅ Chunk 999/1248 summarized. Total summaries so far: 999\n",
      "✅ Chunk 1000/1248 summarized. Total summaries so far: 1000\n",
      "✅ Chunk 1001/1248 summarized. Total summaries so far: 1001\n",
      "✅ Chunk 1002/1248 summarized. Total summaries so far: 1002\n",
      "✅ Chunk 1003/1248 summarized. Total summaries so far: 1003\n",
      "✅ Chunk 1004/1248 summarized. Total summaries so far: 1004\n",
      "✅ Chunk 1005/1248 summarized. Total summaries so far: 1005\n",
      "✅ Chunk 1006/1248 summarized. Total summaries so far: 1006\n",
      "✅ Chunk 1007/1248 summarized. Total summaries so far: 1007\n",
      "✅ Chunk 1008/1248 summarized. Total summaries so far: 1008\n",
      "✅ Chunk 1009/1248 summarized. Total summaries so far: 1009\n",
      "✅ Chunk 1010/1248 summarized. Total summaries so far: 1010\n",
      "✅ Chunk 1011/1248 summarized. Total summaries so far: 1011\n",
      "✅ Chunk 1012/1248 summarized. Total summaries so far: 1012\n",
      "✅ Chunk 1013/1248 summarized. Total summaries so far: 1013\n",
      "✅ Chunk 1014/1248 summarized. Total summaries so far: 1014\n",
      "✅ Chunk 1015/1248 summarized. Total summaries so far: 1015\n",
      "✅ Chunk 1016/1248 summarized. Total summaries so far: 1016\n",
      "✅ Chunk 1017/1248 summarized. Total summaries so far: 1017\n",
      "✅ Chunk 1018/1248 summarized. Total summaries so far: 1018\n",
      "✅ Chunk 1019/1248 summarized. Total summaries so far: 1019\n",
      "✅ Chunk 1020/1248 summarized. Total summaries so far: 1020\n",
      "✅ Chunk 1021/1248 summarized. Total summaries so far: 1021\n",
      "✅ Chunk 1022/1248 summarized. Total summaries so far: 1022\n",
      "✅ Chunk 1023/1248 summarized. Total summaries so far: 1023\n",
      "✅ Chunk 1024/1248 summarized. Total summaries so far: 1024\n",
      "✅ Chunk 1025/1248 summarized. Total summaries so far: 1025\n",
      "✅ Chunk 1026/1248 summarized. Total summaries so far: 1026\n",
      "✅ Chunk 1027/1248 summarized. Total summaries so far: 1027\n",
      "✅ Chunk 1028/1248 summarized. Total summaries so far: 1028\n",
      "✅ Chunk 1029/1248 summarized. Total summaries so far: 1029\n",
      "✅ Chunk 1030/1248 summarized. Total summaries so far: 1030\n",
      "✅ Chunk 1031/1248 summarized. Total summaries so far: 1031\n",
      "✅ Chunk 1032/1248 summarized. Total summaries so far: 1032\n",
      "✅ Chunk 1033/1248 summarized. Total summaries so far: 1033\n",
      "✅ Chunk 1034/1248 summarized. Total summaries so far: 1034\n",
      "✅ Chunk 1035/1248 summarized. Total summaries so far: 1035\n",
      "✅ Chunk 1036/1248 summarized. Total summaries so far: 1036\n",
      "✅ Chunk 1037/1248 summarized. Total summaries so far: 1037\n",
      "✅ Chunk 1038/1248 summarized. Total summaries so far: 1038\n",
      "✅ Chunk 1039/1248 summarized. Total summaries so far: 1039\n",
      "✅ Chunk 1040/1248 summarized. Total summaries so far: 1040\n",
      "✅ Chunk 1041/1248 summarized. Total summaries so far: 1041\n",
      "✅ Chunk 1042/1248 summarized. Total summaries so far: 1042\n",
      "✅ Chunk 1043/1248 summarized. Total summaries so far: 1043\n",
      "✅ Chunk 1044/1248 summarized. Total summaries so far: 1044\n",
      "✅ Chunk 1045/1248 summarized. Total summaries so far: 1045\n",
      "✅ Chunk 1046/1248 summarized. Total summaries so far: 1046\n",
      "✅ Chunk 1047/1248 summarized. Total summaries so far: 1047\n",
      "✅ Chunk 1048/1248 summarized. Total summaries so far: 1048\n",
      "✅ Chunk 1049/1248 summarized. Total summaries so far: 1049\n",
      "✅ Chunk 1050/1248 summarized. Total summaries so far: 1050\n",
      "✅ Chunk 1051/1248 summarized. Total summaries so far: 1051\n",
      "✅ Chunk 1052/1248 summarized. Total summaries so far: 1052\n",
      "✅ Chunk 1053/1248 summarized. Total summaries so far: 1053\n",
      "✅ Chunk 1054/1248 summarized. Total summaries so far: 1054\n",
      "✅ Chunk 1055/1248 summarized. Total summaries so far: 1055\n",
      "✅ Chunk 1056/1248 summarized. Total summaries so far: 1056\n",
      "✅ Chunk 1057/1248 summarized. Total summaries so far: 1057\n",
      "✅ Chunk 1058/1248 summarized. Total summaries so far: 1058\n",
      "✅ Chunk 1059/1248 summarized. Total summaries so far: 1059\n",
      "✅ Chunk 1060/1248 summarized. Total summaries so far: 1060\n",
      "✅ Chunk 1061/1248 summarized. Total summaries so far: 1061\n",
      "✅ Chunk 1062/1248 summarized. Total summaries so far: 1062\n",
      "✅ Chunk 1063/1248 summarized. Total summaries so far: 1063\n",
      "✅ Chunk 1064/1248 summarized. Total summaries so far: 1064\n",
      "✅ Chunk 1065/1248 summarized. Total summaries so far: 1065\n",
      "✅ Chunk 1066/1248 summarized. Total summaries so far: 1066\n",
      "✅ Chunk 1067/1248 summarized. Total summaries so far: 1067\n",
      "✅ Chunk 1068/1248 summarized. Total summaries so far: 1068\n",
      "✅ Chunk 1069/1248 summarized. Total summaries so far: 1069\n",
      "✅ Chunk 1070/1248 summarized. Total summaries so far: 1070\n",
      "✅ Chunk 1071/1248 summarized. Total summaries so far: 1071\n",
      "✅ Chunk 1072/1248 summarized. Total summaries so far: 1072\n",
      "✅ Chunk 1073/1248 summarized. Total summaries so far: 1073\n",
      "✅ Chunk 1074/1248 summarized. Total summaries so far: 1074\n",
      "✅ Chunk 1075/1248 summarized. Total summaries so far: 1075\n",
      "✅ Chunk 1076/1248 summarized. Total summaries so far: 1076\n",
      "✅ Chunk 1077/1248 summarized. Total summaries so far: 1077\n",
      "✅ Chunk 1078/1248 summarized. Total summaries so far: 1078\n",
      "✅ Chunk 1079/1248 summarized. Total summaries so far: 1079\n",
      "✅ Chunk 1080/1248 summarized. Total summaries so far: 1080\n",
      "✅ Chunk 1081/1248 summarized. Total summaries so far: 1081\n",
      "✅ Chunk 1082/1248 summarized. Total summaries so far: 1082\n",
      "✅ Chunk 1083/1248 summarized. Total summaries so far: 1083\n",
      "✅ Chunk 1084/1248 summarized. Total summaries so far: 1084\n",
      "✅ Chunk 1085/1248 summarized. Total summaries so far: 1085\n",
      "✅ Chunk 1086/1248 summarized. Total summaries so far: 1086\n",
      "✅ Chunk 1087/1248 summarized. Total summaries so far: 1087\n",
      "✅ Chunk 1088/1248 summarized. Total summaries so far: 1088\n",
      "✅ Chunk 1089/1248 summarized. Total summaries so far: 1089\n",
      "✅ Chunk 1090/1248 summarized. Total summaries so far: 1090\n",
      "✅ Chunk 1091/1248 summarized. Total summaries so far: 1091\n",
      "✅ Chunk 1092/1248 summarized. Total summaries so far: 1092\n",
      "✅ Chunk 1093/1248 summarized. Total summaries so far: 1093\n",
      "✅ Chunk 1094/1248 summarized. Total summaries so far: 1094\n",
      "✅ Chunk 1095/1248 summarized. Total summaries so far: 1095\n",
      "✅ Chunk 1096/1248 summarized. Total summaries so far: 1096\n",
      "✅ Chunk 1097/1248 summarized. Total summaries so far: 1097\n",
      "✅ Chunk 1098/1248 summarized. Total summaries so far: 1098\n",
      "✅ Chunk 1099/1248 summarized. Total summaries so far: 1099\n",
      "✅ Chunk 1100/1248 summarized. Total summaries so far: 1100\n",
      "✅ Chunk 1101/1248 summarized. Total summaries so far: 1101\n",
      "✅ Chunk 1102/1248 summarized. Total summaries so far: 1102\n",
      "✅ Chunk 1103/1248 summarized. Total summaries so far: 1103\n",
      "✅ Chunk 1104/1248 summarized. Total summaries so far: 1104\n",
      "✅ Chunk 1105/1248 summarized. Total summaries so far: 1105\n",
      "✅ Chunk 1106/1248 summarized. Total summaries so far: 1106\n",
      "✅ Chunk 1107/1248 summarized. Total summaries so far: 1107\n",
      "✅ Chunk 1108/1248 summarized. Total summaries so far: 1108\n",
      "✅ Chunk 1109/1248 summarized. Total summaries so far: 1109\n",
      "✅ Chunk 1110/1248 summarized. Total summaries so far: 1110\n",
      "✅ Chunk 1111/1248 summarized. Total summaries so far: 1111\n",
      "✅ Chunk 1112/1248 summarized. Total summaries so far: 1112\n",
      "✅ Chunk 1113/1248 summarized. Total summaries so far: 1113\n",
      "✅ Chunk 1114/1248 summarized. Total summaries so far: 1114\n",
      "✅ Chunk 1115/1248 summarized. Total summaries so far: 1115\n",
      "✅ Chunk 1116/1248 summarized. Total summaries so far: 1116\n",
      "✅ Chunk 1117/1248 summarized. Total summaries so far: 1117\n",
      "✅ Chunk 1118/1248 summarized. Total summaries so far: 1118\n",
      "✅ Chunk 1119/1248 summarized. Total summaries so far: 1119\n",
      "✅ Chunk 1120/1248 summarized. Total summaries so far: 1120\n",
      "✅ Chunk 1121/1248 summarized. Total summaries so far: 1121\n",
      "✅ Chunk 1122/1248 summarized. Total summaries so far: 1122\n",
      "✅ Chunk 1123/1248 summarized. Total summaries so far: 1123\n",
      "✅ Chunk 1124/1248 summarized. Total summaries so far: 1124\n",
      "✅ Chunk 1125/1248 summarized. Total summaries so far: 1125\n",
      "✅ Chunk 1126/1248 summarized. Total summaries so far: 1126\n",
      "✅ Chunk 1127/1248 summarized. Total summaries so far: 1127\n",
      "✅ Chunk 1128/1248 summarized. Total summaries so far: 1128\n",
      "✅ Chunk 1129/1248 summarized. Total summaries so far: 1129\n",
      "✅ Chunk 1130/1248 summarized. Total summaries so far: 1130\n",
      "✅ Chunk 1131/1248 summarized. Total summaries so far: 1131\n",
      "✅ Chunk 1132/1248 summarized. Total summaries so far: 1132\n",
      "✅ Chunk 1133/1248 summarized. Total summaries so far: 1133\n",
      "✅ Chunk 1134/1248 summarized. Total summaries so far: 1134\n",
      "✅ Chunk 1135/1248 summarized. Total summaries so far: 1135\n",
      "✅ Chunk 1136/1248 summarized. Total summaries so far: 1136\n",
      "✅ Chunk 1137/1248 summarized. Total summaries so far: 1137\n",
      "✅ Chunk 1138/1248 summarized. Total summaries so far: 1138\n",
      "✅ Chunk 1139/1248 summarized. Total summaries so far: 1139\n",
      "✅ Chunk 1140/1248 summarized. Total summaries so far: 1140\n",
      "✅ Chunk 1141/1248 summarized. Total summaries so far: 1141\n",
      "✅ Chunk 1142/1248 summarized. Total summaries so far: 1142\n",
      "✅ Chunk 1143/1248 summarized. Total summaries so far: 1143\n",
      "✅ Chunk 1144/1248 summarized. Total summaries so far: 1144\n",
      "✅ Chunk 1145/1248 summarized. Total summaries so far: 1145\n",
      "✅ Chunk 1146/1248 summarized. Total summaries so far: 1146\n",
      "✅ Chunk 1147/1248 summarized. Total summaries so far: 1147\n",
      "✅ Chunk 1148/1248 summarized. Total summaries so far: 1148\n",
      "✅ Chunk 1149/1248 summarized. Total summaries so far: 1149\n",
      "✅ Chunk 1150/1248 summarized. Total summaries so far: 1150\n",
      "✅ Chunk 1151/1248 summarized. Total summaries so far: 1151\n",
      "✅ Chunk 1152/1248 summarized. Total summaries so far: 1152\n",
      "✅ Chunk 1153/1248 summarized. Total summaries so far: 1153\n",
      "✅ Chunk 1154/1248 summarized. Total summaries so far: 1154\n",
      "✅ Chunk 1155/1248 summarized. Total summaries so far: 1155\n",
      "✅ Chunk 1156/1248 summarized. Total summaries so far: 1156\n",
      "✅ Chunk 1157/1248 summarized. Total summaries so far: 1157\n",
      "✅ Chunk 1158/1248 summarized. Total summaries so far: 1158\n",
      "✅ Chunk 1159/1248 summarized. Total summaries so far: 1159\n",
      "✅ Chunk 1160/1248 summarized. Total summaries so far: 1160\n",
      "✅ Chunk 1161/1248 summarized. Total summaries so far: 1161\n",
      "✅ Chunk 1162/1248 summarized. Total summaries so far: 1162\n",
      "✅ Chunk 1163/1248 summarized. Total summaries so far: 1163\n",
      "✅ Chunk 1164/1248 summarized. Total summaries so far: 1164\n",
      "✅ Chunk 1165/1248 summarized. Total summaries so far: 1165\n",
      "✅ Chunk 1166/1248 summarized. Total summaries so far: 1166\n",
      "✅ Chunk 1167/1248 summarized. Total summaries so far: 1167\n",
      "✅ Chunk 1168/1248 summarized. Total summaries so far: 1168\n",
      "✅ Chunk 1169/1248 summarized. Total summaries so far: 1169\n",
      "✅ Chunk 1170/1248 summarized. Total summaries so far: 1170\n",
      "✅ Chunk 1171/1248 summarized. Total summaries so far: 1171\n",
      "✅ Chunk 1172/1248 summarized. Total summaries so far: 1172\n",
      "✅ Chunk 1173/1248 summarized. Total summaries so far: 1173\n",
      "✅ Chunk 1174/1248 summarized. Total summaries so far: 1174\n",
      "✅ Chunk 1175/1248 summarized. Total summaries so far: 1175\n",
      "✅ Chunk 1176/1248 summarized. Total summaries so far: 1176\n",
      "✅ Chunk 1177/1248 summarized. Total summaries so far: 1177\n",
      "✅ Chunk 1178/1248 summarized. Total summaries so far: 1178\n",
      "✅ Chunk 1179/1248 summarized. Total summaries so far: 1179\n",
      "✅ Chunk 1180/1248 summarized. Total summaries so far: 1180\n",
      "✅ Chunk 1181/1248 summarized. Total summaries so far: 1181\n",
      "✅ Chunk 1182/1248 summarized. Total summaries so far: 1182\n",
      "✅ Chunk 1183/1248 summarized. Total summaries so far: 1183\n",
      "✅ Chunk 1184/1248 summarized. Total summaries so far: 1184\n",
      "✅ Chunk 1185/1248 summarized. Total summaries so far: 1185\n",
      "✅ Chunk 1186/1248 summarized. Total summaries so far: 1186\n",
      "✅ Chunk 1187/1248 summarized. Total summaries so far: 1187\n",
      "✅ Chunk 1188/1248 summarized. Total summaries so far: 1188\n",
      "✅ Chunk 1189/1248 summarized. Total summaries so far: 1189\n",
      "✅ Chunk 1190/1248 summarized. Total summaries so far: 1190\n",
      "✅ Chunk 1191/1248 summarized. Total summaries so far: 1191\n",
      "✅ Chunk 1192/1248 summarized. Total summaries so far: 1192\n",
      "✅ Chunk 1193/1248 summarized. Total summaries so far: 1193\n",
      "✅ Chunk 1194/1248 summarized. Total summaries so far: 1194\n",
      "✅ Chunk 1195/1248 summarized. Total summaries so far: 1195\n",
      "✅ Chunk 1196/1248 summarized. Total summaries so far: 1196\n",
      "✅ Chunk 1197/1248 summarized. Total summaries so far: 1197\n",
      "✅ Chunk 1198/1248 summarized. Total summaries so far: 1198\n",
      "✅ Chunk 1199/1248 summarized. Total summaries so far: 1199\n",
      "✅ Chunk 1200/1248 summarized. Total summaries so far: 1200\n",
      "✅ Chunk 1201/1248 summarized. Total summaries so far: 1201\n",
      "✅ Chunk 1202/1248 summarized. Total summaries so far: 1202\n",
      "✅ Chunk 1203/1248 summarized. Total summaries so far: 1203\n",
      "✅ Chunk 1204/1248 summarized. Total summaries so far: 1204\n",
      "✅ Chunk 1205/1248 summarized. Total summaries so far: 1205\n",
      "✅ Chunk 1206/1248 summarized. Total summaries so far: 1206\n",
      "✅ Chunk 1207/1248 summarized. Total summaries so far: 1207\n",
      "✅ Chunk 1208/1248 summarized. Total summaries so far: 1208\n",
      "✅ Chunk 1209/1248 summarized. Total summaries so far: 1209\n",
      "✅ Chunk 1210/1248 summarized. Total summaries so far: 1210\n",
      "✅ Chunk 1211/1248 summarized. Total summaries so far: 1211\n",
      "✅ Chunk 1212/1248 summarized. Total summaries so far: 1212\n",
      "✅ Chunk 1213/1248 summarized. Total summaries so far: 1213\n",
      "✅ Chunk 1214/1248 summarized. Total summaries so far: 1214\n",
      "✅ Chunk 1215/1248 summarized. Total summaries so far: 1215\n",
      "✅ Chunk 1216/1248 summarized. Total summaries so far: 1216\n",
      "✅ Chunk 1217/1248 summarized. Total summaries so far: 1217\n",
      "✅ Chunk 1218/1248 summarized. Total summaries so far: 1218\n",
      "✅ Chunk 1219/1248 summarized. Total summaries so far: 1219\n",
      "✅ Chunk 1220/1248 summarized. Total summaries so far: 1220\n",
      "✅ Chunk 1221/1248 summarized. Total summaries so far: 1221\n",
      "✅ Chunk 1222/1248 summarized. Total summaries so far: 1222\n",
      "✅ Chunk 1223/1248 summarized. Total summaries so far: 1223\n",
      "✅ Chunk 1224/1248 summarized. Total summaries so far: 1224\n",
      "✅ Chunk 1225/1248 summarized. Total summaries so far: 1225\n",
      "✅ Chunk 1226/1248 summarized. Total summaries so far: 1226\n",
      "✅ Chunk 1227/1248 summarized. Total summaries so far: 1227\n",
      "✅ Chunk 1228/1248 summarized. Total summaries so far: 1228\n",
      "✅ Chunk 1229/1248 summarized. Total summaries so far: 1229\n",
      "✅ Chunk 1230/1248 summarized. Total summaries so far: 1230\n",
      "✅ Chunk 1231/1248 summarized. Total summaries so far: 1231\n",
      "✅ Chunk 1232/1248 summarized. Total summaries so far: 1232\n",
      "✅ Chunk 1233/1248 summarized. Total summaries so far: 1233\n",
      "✅ Chunk 1234/1248 summarized. Total summaries so far: 1234\n",
      "✅ Chunk 1235/1248 summarized. Total summaries so far: 1235\n",
      "✅ Chunk 1236/1248 summarized. Total summaries so far: 1236\n",
      "✅ Chunk 1237/1248 summarized. Total summaries so far: 1237\n",
      "✅ Chunk 1238/1248 summarized. Total summaries so far: 1238\n",
      "✅ Chunk 1239/1248 summarized. Total summaries so far: 1239\n",
      "✅ Chunk 1240/1248 summarized. Total summaries so far: 1240\n",
      "✅ Chunk 1241/1248 summarized. Total summaries so far: 1241\n",
      "✅ Chunk 1242/1248 summarized. Total summaries so far: 1242\n",
      "✅ Chunk 1243/1248 summarized. Total summaries so far: 1243\n",
      "✅ Chunk 1244/1248 summarized. Total summaries so far: 1244\n",
      "✅ Chunk 1245/1248 summarized. Total summaries so far: 1245\n",
      "✅ Chunk 1246/1248 summarized. Total summaries so far: 1246\n",
      "✅ Chunk 1247/1248 summarized. Total summaries so far: 1247\n",
      "✅ Chunk 1248/1248 summarized. Total summaries so far: 1248\n",
      "\n",
      "🔄 Generating embeddings on cuda...\n",
      "   Embedded 32/1248\n",
      "   Embedded 64/1248\n",
      "   Embedded 96/1248\n",
      "   Embedded 128/1248\n",
      "   Embedded 160/1248\n",
      "   Embedded 192/1248\n",
      "   Embedded 224/1248\n",
      "   Embedded 256/1248\n",
      "   Embedded 288/1248\n",
      "   Embedded 320/1248\n",
      "   Embedded 352/1248\n",
      "   Embedded 384/1248\n",
      "   Embedded 416/1248\n",
      "   Embedded 448/1248\n",
      "   Embedded 480/1248\n",
      "   Embedded 512/1248\n",
      "   Embedded 544/1248\n",
      "   Embedded 576/1248\n",
      "   Embedded 608/1248\n",
      "   Embedded 640/1248\n",
      "   Embedded 672/1248\n",
      "   Embedded 704/1248\n",
      "   Embedded 736/1248\n",
      "   Embedded 768/1248\n",
      "   Embedded 800/1248\n",
      "   Embedded 832/1248\n",
      "   Embedded 864/1248\n",
      "   Embedded 896/1248\n",
      "   Embedded 928/1248\n",
      "   Embedded 960/1248\n",
      "   Embedded 992/1248\n",
      "   Embedded 1024/1248\n",
      "   Embedded 1056/1248\n",
      "   Embedded 1088/1248\n",
      "   Embedded 1120/1248\n",
      "   Embedded 1152/1248\n",
      "   Embedded 1184/1248\n",
      "   Embedded 1216/1248\n",
      "   Embedded 1248/1248\n",
      "\n",
      "🚀 Building FAISS index on cuda...\n",
      "   ✅ FAISS index built with 1248 vectors\n",
      "\n",
      "💾 Saving index and docstore...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'faiss_layer2/index.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 76\u001b[39m\n\u001b[32m     73\u001b[39m docstore = {s[\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m]: s[\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m summary_texts}\n\u001b[32m     74\u001b[39m index_to_docstore_id = {i: s[\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i, s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(summary_texts)}\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfaiss_layer2/index.pkl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     77\u001b[39m     pickle.dump([docstore, index_to_docstore_id], f)\n\u001b[32m     79\u001b[39m faiss.write_index(index, \u001b[33m\"\u001b[39m\u001b[33mfaiss_layer2/index.faiss\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Madam\\Shams\\final_shams\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:343\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    338\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'faiss_layer2/index.pkl'"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "import pickle\n",
    "import faiss\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Check GPU availability\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"🔧 Using device: {device}\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\\n\")\n",
    "\n",
    "# Initialize embeddings model with GPU support\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_kwargs={'device': device},\n",
    "    encode_kwargs={'device': device, 'batch_size': 32}  # Batch processing for speed\n",
    ")\n",
    "\n",
    "# Initialize LLM (Ollama handles GPU automatically if available)\n",
    "llm = Ollama(model=\"gemma3:4b\")\n",
    "\n",
    "# Load raw chunks\n",
    "print(\"📂 Loading raw chunks...\")\n",
    "with open(\"faiss_layer1/index.pkl\", \"rb\") as f:\n",
    "    raw_store_data = pickle.load(f)\n",
    "raw_docstore = raw_store_data[0]\n",
    "\n",
    "summary_texts = []\n",
    "total_chunks = len(raw_docstore._dict)\n",
    "print(f\"Total chunks to summarize: {total_chunks}\\n\")\n",
    "\n",
    "# Summarize each chunk and show progress\n",
    "for i, doc_id in enumerate(raw_docstore._dict.keys(), start=1):\n",
    "    chunk = raw_docstore._dict[doc_id]\n",
    "    try:\n",
    "        summary = llm.invoke(\n",
    "            f\"Summarize this chunk factually and do not add any fictional events: {chunk}\"\n",
    "        )\n",
    "        summary_texts.append({\"id\": doc_id, \"text\": summary})\n",
    "        print(f\"✅ Chunk {i}/{total_chunks} summarized. Total summaries so far: {len(summary_texts)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠ Failed chunk {i}/{total_chunks} (ID: {doc_id}): {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n🔄 Generating embeddings on {device}...\")\n",
    "\n",
    "# Build embeddings in batches for efficiency\n",
    "batch_size = 32\n",
    "summary_vectors = []\n",
    "for i in range(0, len(summary_texts), batch_size):\n",
    "    batch = [s[\"text\"] for s in summary_texts[i:i+batch_size]]\n",
    "    batch_vectors = embedding_model.embed_documents(batch)\n",
    "    summary_vectors.extend(batch_vectors)\n",
    "    print(f\"   Embedded {min(i+batch_size, len(summary_texts))}/{len(summary_texts)}\")\n",
    "\n",
    "# Convert to numpy array\n",
    "summary_vectors_np = np.array(summary_vectors).astype(\"float32\")\n",
    "dimension = summary_vectors_np.shape[1]\n",
    "\n",
    "print(f\"\\n🚀 Building FAISS index on {device}...\")\n",
    "\n",
    "# FAISS indexing (CPU-based, but embeddings were generated on GPU)\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(summary_vectors_np)\n",
    "print(f\"   ✅ FAISS index built with {len(summary_vectors_np)} vectors\")\n",
    "\n",
    "# Save docstore + index mapping\n",
    "print(\"\\n💾 Saving index and docstore...\")\n",
    "docstore = {s[\"id\"]: s[\"text\"] for s in summary_texts}\n",
    "index_to_docstore_id = {i: s[\"id\"] for i, s in enumerate(summary_texts)}\n",
    "\n",
    "with open(\"faiss_layer2/index.pkl\", \"wb\") as f:\n",
    "    pickle.dump([docstore, index_to_docstore_id], f)\n",
    "\n",
    "faiss.write_index(index, \"faiss_layer2/index.faiss\")\n",
    "\n",
    "print(f\"\\n🎉 Summary layer rebuild complete!\")\n",
    "print(f\"Total successful summaries/embeddings: {len(summary_texts)}/{total_chunks}\")\n",
    "print(f\"Index dimension: {dimension}\")\n",
    "print(f\"Device used: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e31e8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index and metadata saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import faiss\n",
    "\n",
    "# make sure directory exists\n",
    "os.makedirs(\"faiss_layer2\", exist_ok=True)\n",
    "\n",
    "# save docstore + mapping\n",
    "with open(\"faiss_layer2/index.pkl\", \"wb\") as f:\n",
    "    pickle.dump([docstore, index_to_docstore_id], f)\n",
    "\n",
    "# save FAISS index\n",
    "faiss.write_index(index, \"faiss_layer2/index.faiss\")\n",
    "\n",
    "print(\"Index and metadata saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd06dd3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
